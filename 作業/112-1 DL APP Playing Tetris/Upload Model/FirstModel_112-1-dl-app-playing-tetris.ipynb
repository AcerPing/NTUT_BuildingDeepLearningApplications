{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df92a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:00:15.428359Z",
     "iopub.status.busy": "2023-12-05T07:00:15.427926Z",
     "iopub.status.idle": "2023-12-05T07:00:15.633464Z",
     "shell.execute_reply": "2023-12-05T07:00:15.632642Z"
    },
    "papermill": {
     "duration": 0.218134,
     "end_time": "2023-12-05T07:00:15.635953",
     "exception": false,
     "start_time": "2023-12-05T07:00:15.417819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import socket\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c55a1",
   "metadata": {
    "papermill": {
     "duration": 0.007094,
     "end_time": "2023-12-05T07:00:15.651376",
     "exception": false,
     "start_time": "2023-12-05T07:00:15.644282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Stable Baseline3 version >= 2.0.0a5\n",
    "#### Note some SB3 versions are not compatible with Gymnasium interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbdf17b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:00:15.668131Z",
     "iopub.status.busy": "2023-12-05T07:00:15.667510Z",
     "iopub.status.idle": "2023-12-05T07:00:50.631116Z",
     "shell.execute_reply": "2023-12-05T07:00:50.629998Z"
    },
    "papermill": {
     "duration": 34.975221,
     "end_time": "2023-12-05T07:00:50.633885",
     "exception": false,
     "start_time": "2023-12-05T07:00:15.658664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3[extra]>=2.0.0a5\r\n",
      "  Obtaining dependency information for stable-baselines3[extra]>=2.0.0a5 from https://files.pythonhosted.org/packages/1e/43/d4b83e644c7e42d90d76a1987fb98a2ab286a2b5593350210ca8efcc378e/stable_baselines3-2.2.1-py3-none-any.whl.metadata\r\n",
      "  Downloading stable_baselines3-2.2.1-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[extra]>=2.0.0a5)\r\n",
      "  Obtaining dependency information for gymnasium<0.30,>=0.28.1 from https://files.pythonhosted.org/packages/a8/4d/3cbfd81ed84db450dbe73a89afcd8bc405273918415649ac6683356afe92/gymnasium-0.29.1-py3-none-any.whl.metadata\r\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (1.24.3)\r\n",
      "Requirement already satisfied: torch>=1.13 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (2.0.0+cpu)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (2.2.1)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (2.0.3)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (3.7.3)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (4.8.1.78)\r\n",
      "Collecting pygame (from stable-baselines3[extra]>=2.0.0a5)\r\n",
      "  Obtaining dependency information for pygame from https://files.pythonhosted.org/packages/c8/c7/0d77e0e327bf09c12f445f92f5bad0b447375d7b836c5bac5255ead8436f/pygame-2.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading pygame-2.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (2.13.0)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (5.9.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (4.66.1)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (13.5.2)\r\n",
      "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra]>=2.0.0a5)\r\n",
      "  Obtaining dependency information for shimmy[atari]~=1.3.0 from https://files.pythonhosted.org/packages/dc/f9/07ef16463db14ac1b30f149c379760f5cacf3fc677b295d29a92f3127914/Shimmy-1.3.0-py3-none-any.whl.metadata\r\n",
      "  Downloading Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5) (10.1.0)\r\n",
      "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra]>=2.0.0a5)\r\n",
      "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a5) (8.1.7)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a5) (2.31.0)\r\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a5)\r\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a5) (4.5.0)\r\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a5)\r\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\r\n",
      "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a5)\r\n",
      "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (1.57.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (2.22.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (3.4.4)\r\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (68.1.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (0.7.1)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (3.0.1)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (0.41.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5) (3.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5) (3.1.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a5) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a5) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a5) (4.42.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a5) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a5) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a5) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a5) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3[extra]>=2.0.0a5) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3[extra]>=2.0.0a5) (2023.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->stable-baselines3[extra]>=2.0.0a5) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->stable-baselines3[extra]>=2.0.0a5) (2.16.1)\r\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a5) (5.13.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (4.9)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (1.26.15)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (1.3.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5) (0.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a5) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a5) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a5) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13->stable-baselines3[extra]>=2.0.0a5) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5) (3.2.2)\r\n",
      "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pygame-2.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading stable_baselines3-2.2.1-py3-none-any.whl (181 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\r\n",
      "Building wheels for collected packages: AutoROM.accept-rom-license\r\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=38a979d1945e3a85f24d29b21b8328120836c245be306840534dc4374263b3bc\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\r\n",
      "Successfully built AutoROM.accept-rom-license\r\n",
      "Installing collected packages: farama-notifications, pygame, gymnasium, ale-py, shimmy, AutoROM.accept-rom-license, autorom, stable-baselines3\r\n",
      "  Attempting uninstall: gymnasium\r\n",
      "    Found existing installation: Gymnasium 0.26.3\r\n",
      "    Uninstalling Gymnasium-0.26.3:\r\n",
      "      Successfully uninstalled Gymnasium-0.26.3\r\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 farama-notifications-0.0.4 gymnasium-0.29.1 pygame-2.5.2 shimmy-1.3.0 stable-baselines3-2.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"stable-baselines3[extra] >= 2.0.0a5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86735876",
   "metadata": {
    "papermill": {
     "duration": 0.012789,
     "end_time": "2023-12-05T07:00:50.659838",
     "exception": false,
     "start_time": "2023-12-05T07:00:50.647049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run the Java Tetris Server using subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3be004b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:00:50.687813Z",
     "iopub.status.busy": "2023-12-05T07:00:50.687370Z",
     "iopub.status.idle": "2023-12-05T07:00:51.790679Z",
     "shell.execute_reply": "2023-12-05T07:00:51.789052Z"
    },
    "papermill": {
     "duration": 1.121148,
     "end_time": "2023-12-05T07:00:51.793909",
     "exception": false,
     "start_time": "2023-12-05T07:00:50.672761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can download latest server from AIoTLab website. Currently (2023/12/5) is v0.6\n",
    "# !wget http://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
    "!cp /kaggle/input/112-1-ntut-dl-app-hw4/TetrisTCPserver_v0.6.jar ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9bb50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:00:51.822240Z",
     "iopub.status.busy": "2023-12-05T07:00:51.821822Z",
     "iopub.status.idle": "2023-12-05T07:00:51.834376Z",
     "shell.execute_reply": "2023-12-05T07:00:51.833639Z"
    },
    "papermill": {
     "duration": 0.02969,
     "end_time": "2023-12-05T07:00:51.836759",
     "exception": false,
     "start_time": "2023-12-05T07:00:51.807069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['java', '-jar', 'TetrisTCPserver_v0.6.jar']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.Popen([\"java\",\"-jar\",\"TetrisTCPserver_v0.6.jar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9b334",
   "metadata": {
    "papermill": {
     "duration": 0.014774,
     "end_time": "2023-12-05T07:00:51.870907",
     "exception": false,
     "start_time": "2023-12-05T07:00:51.856133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create our own Tetris Test environment by inheriting Gym class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8413b872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:00:51.910801Z",
     "iopub.status.busy": "2023-12-05T07:00:51.910020Z",
     "iopub.status.idle": "2023-12-05T07:00:52.737330Z",
     "shell.execute_reply": "2023-12-05T07:00:52.736219Z"
    },
    "papermill": {
     "duration": 0.850433,
     "end_time": "2023-12-05T07:00:52.740186",
     "exception": false,
     "start_time": "2023-12-05T07:00:51.889753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tetris TCP server is listening at 10612\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ec4f7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:00:52.770087Z",
     "iopub.status.busy": "2023-12-05T07:00:52.769669Z",
     "iopub.status.idle": "2023-12-05T07:00:52.794498Z",
     "shell.execute_reply": "2023-12-05T07:00:52.793525Z"
    },
    "papermill": {
     "duration": 0.04241,
     "end_time": "2023-12-05T07:00:52.796887",
     "exception": false,
     "start_time": "2023-12-05T07:00:52.754477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TetrisEnv(gym.Env):\n",
    "    \n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 20}\n",
    "    \n",
    "    '''\n",
    "        The supported actions are\n",
    "        0: move -1\n",
    "        1: move 1\n",
    "        2: rotate 0 // counter-clockwise\n",
    "        3: rotate 1 // clockwise\n",
    "        4: drop down\n",
    "    '''\n",
    "    N_DISCRETE_ACTIONS = 5\n",
    "    \n",
    "    IMG_HEIGHT = 200\n",
    "    IMG_WIDTH = 100\n",
    "    IMG_CHANNELS = 3\n",
    "    \n",
    "\n",
    "    def __init__(self, host_ip=\"127.0.0.1\", host_port=10612):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.action_space = spaces.Discrete(self.N_DISCRETE_ACTIONS)\n",
    "        # Example for using image as input (channel-first; channel-last also works):\n",
    "        self.observation_space = spaces.Box(low=0, high=255,\n",
    "                                            shape=(self.IMG_HEIGHT, self.IMG_WIDTH, self.IMG_CHANNELS), dtype=np.uint8)\n",
    "        self.server_ip = host_ip\n",
    "        self.server_port = host_port\n",
    "            \n",
    "        self.client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.client_sock.connect((self.server_ip, self.server_port))\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.client_sock.sendall(b\"move -1\\n\")\n",
    "        elif action == 1:\n",
    "            self.client_sock.sendall(b\"move 1\\n\")\n",
    "        elif action == 2:\n",
    "            self.client_sock.sendall(b\"rotate 0\\n\")\n",
    "        elif action == 3:\n",
    "            self.client_sock.sendall(b\"rotate 1\\n\")\n",
    "        elif action == 4:\n",
    "            self.client_sock.sendall(b\"drop\\n\")\n",
    "            \n",
    "        terminated, lines, height, holes, observation = self.get_tetris_server_response(self.client_sock)\n",
    "        self.observation = observation\n",
    "        \n",
    "        reward = 0\n",
    "        if action == 4: # Drop reward\n",
    "            reward += 5\n",
    "            \n",
    "        # Negative height reward\n",
    "        if height > self.height:\n",
    "            reward -= (height - self.height)*5\n",
    "        \n",
    "        # Positive hole reduction reward\n",
    "        if holes < self.holes:\n",
    "            reward += (self.holes - holes)*20\n",
    "        \n",
    "        if lines > self.lines_removed:\n",
    "            reward = reward + (lines - self.lines_removed)*1000\n",
    "            self.lines_removed = lines\n",
    "            \n",
    "        self.reward = self.reward + reward\n",
    "        self.holes = holes\n",
    "        self.height = height\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        return (observation, reward, terminated, truncated, info)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.client_sock.sendall(b\"start\\n\")\n",
    "        terminated, lines, height, holes, observation = self.get_tetris_server_response(self.client_sock)\n",
    "        self.observation = observation\n",
    "        self.reward = 0\n",
    "        self.lines_removed = 0\n",
    "        self.holes = 0\n",
    "        self.height = 0\n",
    "        info = {}\n",
    "        return observation, info\n",
    "\n",
    "    def render(self):\n",
    "        ''''''\n",
    "        #if self.render_mode == \"console\":\n",
    "        #    print('Total reward ' + str(self.reward))\n",
    "        '''\n",
    "        if self.render_mode == \"human\":\n",
    "            cv2.imshow(\"Image\", self.observation)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        '''\n",
    "\n",
    "    def close(self):\n",
    "        self.client_sock.close()\n",
    "        \n",
    "    def get_tetris_server_response(self, sock):\n",
    "        is_game_over = (sock.recv(1) == b'\\x01')\n",
    "        removed_lines = int.from_bytes(sock.recv(4), 'big')\n",
    "        height = int.from_bytes(sock.recv(4), 'big')\n",
    "        holes = int.from_bytes(sock.recv(4), 'big')\n",
    "        img_size = int.from_bytes(sock.recv(4), 'big')\n",
    "        img_png = sock.recv(img_size)\n",
    "\n",
    "        nparr = np.frombuffer(img_png, np.uint8)\n",
    "        np_image = cv2.imdecode(nparr, -1)\n",
    "\n",
    "        return is_game_over, removed_lines, height, holes, np_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea714e",
   "metadata": {
    "papermill": {
     "duration": 0.01397,
     "end_time": "2023-12-05T07:00:52.824652",
     "exception": false,
     "start_time": "2023-12-05T07:00:52.810682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Use SB3 env_checker to check our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0184f0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:00:52.853851Z",
     "iopub.status.busy": "2023-12-05T07:00:52.853460Z",
     "iopub.status.idle": "2023-12-05T07:01:11.167029Z",
     "shell.execute_reply": "2023-12-05T07:01:11.165811Z"
    },
    "papermill": {
     "duration": 18.331495,
     "end_time": "2023-12-05T07:01:11.169848",
     "exception": false,
     "start_time": "2023-12-05T07:00:52.838353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client has joined the game\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = TetrisEnv()\n",
    "# It will check your custom environment and output additional warnings if needed\n",
    "# No response may be caused by mismatched action state definition and implementation\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b5f94",
   "metadata": {
    "papermill": {
     "duration": 0.013984,
     "end_time": "2023-12-05T07:01:11.197917",
     "exception": false,
     "start_time": "2023-12-05T07:01:11.183933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Randomly test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0924dc5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:01:11.228762Z",
     "iopub.status.busy": "2023-12-05T07:01:11.228021Z",
     "iopub.status.idle": "2023-12-05T07:01:12.062422Z",
     "shell.execute_reply": "2023-12-05T07:01:12.061383Z"
    },
    "papermill": {
     "duration": 0.853672,
     "end_time": "2023-12-05T07:01:12.065603",
     "exception": false,
     "start_time": "2023-12-05T07:01:11.211931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs, info = env.reset()\n",
    "n_steps = 20\n",
    "for _ in range(n_steps):\n",
    "    # Random action\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    env.render() # We render nothing now\n",
    "    \n",
    "    if terminated:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a6ff13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:01:12.095701Z",
     "iopub.status.busy": "2023-12-05T07:01:12.095305Z",
     "iopub.status.idle": "2023-12-05T07:01:12.413212Z",
     "shell.execute_reply": "2023-12-05T07:01:12.411957Z"
    },
    "papermill": {
     "duration": 0.336045,
     "end_time": "2023-12-05T07:01:12.415850",
     "exception": false,
     "start_time": "2023-12-05T07:01:12.079805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ea5d9234a30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the final screen\n",
    "%matplotlib inline \n",
    "plt.imshow(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8964f60b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:01:12.446756Z",
     "iopub.status.busy": "2023-12-05T07:01:12.445946Z",
     "iopub.status.idle": "2023-12-05T07:01:12.450913Z",
     "shell.execute_reply": "2023-12-05T07:01:12.450002Z"
    },
    "papermill": {
     "duration": 0.022956,
     "end_time": "2023-12-05T07:01:12.453176",
     "exception": false,
     "start_time": "2023-12-05T07:01:12.430220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8a6e6",
   "metadata": {
    "papermill": {
     "duration": 0.013744,
     "end_time": "2023-12-05T07:01:12.481092",
     "exception": false,
     "start_time": "2023-12-05T07:01:12.467348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create an environment with 30 client threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aadc8cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:01:12.512632Z",
     "iopub.status.busy": "2023-12-05T07:01:12.511425Z",
     "iopub.status.idle": "2023-12-05T07:01:12.602790Z",
     "shell.execute_reply": "2023-12-05T07:01:12.600760Z"
    },
    "papermill": {
     "duration": 0.110641,
     "end_time": "2023-12-05T07:01:12.606177",
     "exception": false,
     "start_time": "2023-12-05T07:01:12.495536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n",
      "Client has joined the game\n"
     ]
    }
   ],
   "source": [
    "# Let's try A2C by creating 30 environments\n",
    "vec_env = make_vec_env(TetrisEnv, n_envs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34acbdac",
   "metadata": {
    "papermill": {
     "duration": 0.014238,
     "end_time": "2023-12-05T07:01:12.635230",
     "exception": false,
     "start_time": "2023-12-05T07:01:12.620992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We choose A2C with CNN policy, and train 3,000,000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaa0eb5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T07:01:12.666517Z",
     "iopub.status.busy": "2023-12-05T07:01:12.665237Z",
     "iopub.status.idle": "2023-12-05T12:29:08.187307Z",
     "shell.execute_reply": "2023-12-05T12:29:08.182669Z"
    },
    "papermill": {
     "duration": 19675.541867,
     "end_time": "2023-12-05T12:29:08.191341",
     "exception": false,
     "start_time": "2023-12-05T07:01:12.649474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.1     |\n",
      "|    ep_rew_mean        | -76.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0354  |\n",
      "|    explained_variance | 0.888    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0094  |\n",
      "|    value_loss         | 27.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 116      |\n",
      "|    ep_rew_mean        | -12.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 171      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.185   |\n",
      "|    explained_variance | 0.655    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.167    |\n",
      "|    value_loss         | 33.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 96.7     |\n",
      "|    ep_rew_mean        | 10.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 171      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.415   |\n",
      "|    explained_variance | 0.569    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.192   |\n",
      "|    value_loss         | 20.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 92.5     |\n",
      "|    ep_rew_mean        | -15.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 171      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.383   |\n",
      "|    explained_variance | 0.535    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -1.8     |\n",
      "|    value_loss         | 25.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 73.2     |\n",
      "|    ep_rew_mean        | 13.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 171      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 436      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.507   |\n",
      "|    explained_variance | 0.634    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.182    |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 83.4     |\n",
      "|    ep_rew_mean        | -2.55    |\n",
      "| time/                 |          |\n",
      "|    fps                | 171      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 523      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.3     |\n",
      "|    explained_variance | 0.87     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.153    |\n",
      "|    value_loss         | 4.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 85.5     |\n",
      "|    ep_rew_mean        | 59.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 172      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 610      |\n",
      "|    total_timesteps    | 105000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00238 |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.00546 |\n",
      "|    value_loss         | 19.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.2     |\n",
      "|    ep_rew_mean        | 25.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 172      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 696      |\n",
      "|    total_timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.282   |\n",
      "|    explained_variance | 0.715    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.345   |\n",
      "|    value_loss         | 21.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.7     |\n",
      "|    ep_rew_mean        | 32       |\n",
      "| time/                 |          |\n",
      "|    fps                | 172      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 782      |\n",
      "|    total_timesteps    | 135000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.233   |\n",
      "|    explained_variance | 0.745    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.344   |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 89.1      |\n",
      "|    ep_rew_mean        | -11.6     |\n",
      "| time/                 |           |\n",
      "|    fps                | 172       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 867       |\n",
      "|    total_timesteps    | 150000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.86e-06 |\n",
      "|    explained_variance | 0.96      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 1.1e-06   |\n",
      "|    value_loss         | 22.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | -60.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 173      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 952      |\n",
      "|    total_timesteps    | 165000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0214  |\n",
      "|    explained_variance | 0.928    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.0622   |\n",
      "|    value_loss         | 31       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 88.9     |\n",
      "|    ep_rew_mean        | 15.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 172      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 1042     |\n",
      "|    total_timesteps    | 180000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.193   |\n",
      "|    explained_variance | 0.847    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.148    |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87       |\n",
      "|    ep_rew_mean        | 59.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 172      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 1133     |\n",
      "|    total_timesteps    | 195000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.255   |\n",
      "|    explained_variance | 0.232    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.0834  |\n",
      "|    value_loss         | 63.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 80.7     |\n",
      "|    ep_rew_mean        | 29.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 171      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 1225     |\n",
      "|    total_timesteps    | 210000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.281   |\n",
      "|    explained_variance | 0.859    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.315    |\n",
      "|    value_loss         | 5.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 78.3     |\n",
      "|    ep_rew_mean        | 106      |\n",
      "| time/                 |          |\n",
      "|    fps                | 170      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 1320     |\n",
      "|    total_timesteps    | 225000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.178   |\n",
      "|    explained_variance | 0.89     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.469   |\n",
      "|    value_loss         | 19.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 78.9     |\n",
      "|    ep_rew_mean        | 49.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 169      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 1415     |\n",
      "|    total_timesteps    | 240000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.161   |\n",
      "|    explained_variance | 0.837    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.264   |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 76.4     |\n",
      "|    ep_rew_mean        | 44.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 1511     |\n",
      "|    total_timesteps    | 255000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.151   |\n",
      "|    explained_variance | 0.931    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.0626  |\n",
      "|    value_loss         | 5.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 86.6     |\n",
      "|    ep_rew_mean        | 120      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 1604     |\n",
      "|    total_timesteps    | 270000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.278   |\n",
      "|    explained_variance | 0.883    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.371    |\n",
      "|    value_loss         | 8.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 82       |\n",
      "|    ep_rew_mean        | 142      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 1697     |\n",
      "|    total_timesteps    | 285000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.127   |\n",
      "|    explained_variance | 0.937    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.2     |\n",
      "|    value_loss         | 6.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 80.2     |\n",
      "|    ep_rew_mean        | 86.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 1787     |\n",
      "|    total_timesteps    | 300000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.201   |\n",
      "|    explained_variance | 0.873    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.0697  |\n",
      "|    value_loss         | 5.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 79.9     |\n",
      "|    ep_rew_mean        | 120      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 1875     |\n",
      "|    total_timesteps    | 315000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.166   |\n",
      "|    explained_variance | 0.925    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0696  |\n",
      "|    value_loss         | 3.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.7     |\n",
      "|    ep_rew_mean        | 218      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 1964     |\n",
      "|    total_timesteps    | 330000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.168   |\n",
      "|    explained_variance | 0.928    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.0105  |\n",
      "|    value_loss         | 9.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.1     |\n",
      "|    ep_rew_mean        | 185      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 2052     |\n",
      "|    total_timesteps    | 345000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.155   |\n",
      "|    explained_variance | 0.874    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.0379  |\n",
      "|    value_loss         | 4.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 88.6     |\n",
      "|    ep_rew_mean        | 177      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 2140     |\n",
      "|    total_timesteps    | 360000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.15    |\n",
      "|    explained_variance | 0.0205   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.871    |\n",
      "|    value_loss         | 1.98e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 84.5     |\n",
      "|    ep_rew_mean        | 187      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 2228     |\n",
      "|    total_timesteps    | 375000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.12    |\n",
      "|    explained_variance | 0.929    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.0693  |\n",
      "|    value_loss         | 7.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 94.1     |\n",
      "|    ep_rew_mean        | 195      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 2317     |\n",
      "|    total_timesteps    | 390000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0894  |\n",
      "|    explained_variance | 0.876    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.0976  |\n",
      "|    value_loss         | 8.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 93.5     |\n",
      "|    ep_rew_mean        | 229      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 2406     |\n",
      "|    total_timesteps    | 405000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.156   |\n",
      "|    explained_variance | 0.945    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.268   |\n",
      "|    value_loss         | 4.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 84.8     |\n",
      "|    ep_rew_mean        | 187      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 2498     |\n",
      "|    total_timesteps    | 420000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.127   |\n",
      "|    explained_variance | 0.915    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0535  |\n",
      "|    value_loss         | 6.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 86.3     |\n",
      "|    ep_rew_mean        | 272      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 2588     |\n",
      "|    total_timesteps    | 435000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.215   |\n",
      "|    explained_variance | 0.645    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.136    |\n",
      "|    value_loss         | 43.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 92.8     |\n",
      "|    ep_rew_mean        | 250      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 2677     |\n",
      "|    total_timesteps    | 450000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.101   |\n",
      "|    explained_variance | 0.0334   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.182   |\n",
      "|    value_loss         | 6.76e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 90.4     |\n",
      "|    ep_rew_mean        | 244      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 2764     |\n",
      "|    total_timesteps    | 465000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.123   |\n",
      "|    explained_variance | 0.919    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.249   |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 94.1     |\n",
      "|    ep_rew_mean        | 222      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 2851     |\n",
      "|    total_timesteps    | 480000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.125   |\n",
      "|    explained_variance | 0.938    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.404   |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 93.2     |\n",
      "|    ep_rew_mean        | 206      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 2935     |\n",
      "|    total_timesteps    | 495000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.158   |\n",
      "|    explained_variance | -0.0115  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 6.24     |\n",
      "|    value_loss         | 6.66e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 93.3     |\n",
      "|    ep_rew_mean        | 240      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 3019     |\n",
      "|    total_timesteps    | 510000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.139   |\n",
      "|    explained_variance | 0.0288   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.0786  |\n",
      "|    value_loss         | 8.15e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.4     |\n",
      "|    ep_rew_mean        | 293      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 3107     |\n",
      "|    total_timesteps    | 525000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.17    |\n",
      "|    explained_variance | 0.972    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.0598  |\n",
      "|    value_loss         | 4.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 94.7     |\n",
      "|    ep_rew_mean        | 384      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 3196     |\n",
      "|    total_timesteps    | 540000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.167   |\n",
      "|    explained_variance | 0.924    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.153   |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.7     |\n",
      "|    ep_rew_mean        | 276      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 3285     |\n",
      "|    total_timesteps    | 555000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.105   |\n",
      "|    explained_variance | 0.964    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.146   |\n",
      "|    value_loss         | 4.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 89.2     |\n",
      "|    ep_rew_mean        | 290      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 3374     |\n",
      "|    total_timesteps    | 570000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0775  |\n",
      "|    explained_variance | 0.0343   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.124   |\n",
      "|    value_loss         | 6.66e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 90.5     |\n",
      "|    ep_rew_mean        | 285      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 3463     |\n",
      "|    total_timesteps    | 585000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.101   |\n",
      "|    explained_variance | 0.0301   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 3.29     |\n",
      "|    value_loss         | 3.5e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 101      |\n",
      "|    ep_rew_mean        | 373      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 3550     |\n",
      "|    total_timesteps    | 600000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0922  |\n",
      "|    explained_variance | 0.959    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.484   |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.6     |\n",
      "|    ep_rew_mean        | 258      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 3640     |\n",
      "|    total_timesteps    | 615000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.134   |\n",
      "|    explained_variance | -0.0136  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 1.84     |\n",
      "|    value_loss         | 2.61e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.8     |\n",
      "|    ep_rew_mean        | 362      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 3730     |\n",
      "|    total_timesteps    | 630000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0961  |\n",
      "|    explained_variance | 0.934    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.156   |\n",
      "|    value_loss         | 13.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 94.4     |\n",
      "|    ep_rew_mean        | 340      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 3822     |\n",
      "|    total_timesteps    | 645000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0993  |\n",
      "|    explained_variance | 0.967    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.0164  |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 97.2     |\n",
      "|    ep_rew_mean        | 371      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 3912     |\n",
      "|    total_timesteps    | 660000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0833  |\n",
      "|    explained_variance | 0.0504   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.115    |\n",
      "|    value_loss         | 1.32e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 92.3     |\n",
      "|    ep_rew_mean        | 338      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 4002     |\n",
      "|    total_timesteps    | 675000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.107   |\n",
      "|    explained_variance | 0.0226   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.0541   |\n",
      "|    value_loss         | 3.36e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 98.5      |\n",
      "|    ep_rew_mean        | 495       |\n",
      "| time/                 |           |\n",
      "|    fps                | 168       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 4093      |\n",
      "|    total_timesteps    | 690000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0646   |\n",
      "|    explained_variance | -0.000255 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 0.117     |\n",
      "|    value_loss         | 2.61e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.5     |\n",
      "|    ep_rew_mean        | 424      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 4182     |\n",
      "|    total_timesteps    | 705000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.072   |\n",
      "|    explained_variance | 0.961    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.0735  |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.4     |\n",
      "|    ep_rew_mean        | 414      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 4272     |\n",
      "|    total_timesteps    | 720000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0911  |\n",
      "|    explained_variance | -0.0252  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.123    |\n",
      "|    value_loss         | 6.09e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 92.7     |\n",
      "|    ep_rew_mean        | 275      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 4374     |\n",
      "|    total_timesteps    | 735000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.126   |\n",
      "|    explained_variance | 0.949    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.344   |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.4     |\n",
      "|    ep_rew_mean        | 402      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 4463     |\n",
      "|    total_timesteps    | 750000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.071   |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.0789  |\n",
      "|    value_loss         | 7.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.8     |\n",
      "|    ep_rew_mean        | 373      |\n",
      "| time/                 |          |\n",
      "|    fps                | 168      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 4551     |\n",
      "|    total_timesteps    | 765000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0662  |\n",
      "|    explained_variance | 0.961    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.141   |\n",
      "|    value_loss         | 5.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 96.9     |\n",
      "|    ep_rew_mean        | 453      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 4642     |\n",
      "|    total_timesteps    | 780000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0669  |\n",
      "|    explained_variance | 0.959    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.0792  |\n",
      "|    value_loss         | 4.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 531      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 4733     |\n",
      "|    total_timesteps    | 795000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0708  |\n",
      "|    explained_variance | 0.0334   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.131   |\n",
      "|    value_loss         | 1.33e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 114      |\n",
      "|    ep_rew_mean        | 376      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 4827     |\n",
      "|    total_timesteps    | 810000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.11    |\n",
      "|    explained_variance | 0.0192   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.3     |\n",
      "|    value_loss         | 3.62e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.7     |\n",
      "|    ep_rew_mean        | 476      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 4918     |\n",
      "|    total_timesteps    | 825000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0391  |\n",
      "|    explained_variance | 0.047    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.0542  |\n",
      "|    value_loss         | 2.78e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 447      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 5017     |\n",
      "|    total_timesteps    | 840000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0802  |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.0092   |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 91.8      |\n",
      "|    ep_rew_mean        | 402       |\n",
      "| time/                 |           |\n",
      "|    fps                | 167       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 5108      |\n",
      "|    total_timesteps    | 855000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0662   |\n",
      "|    explained_variance | -0.000309 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -0.121    |\n",
      "|    value_loss         | 3.39e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 96.5     |\n",
      "|    ep_rew_mean        | 477      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 5202     |\n",
      "|    total_timesteps    | 870000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0677  |\n",
      "|    explained_variance | -0.00794 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 10.3     |\n",
      "|    value_loss         | 1.98e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.4     |\n",
      "|    ep_rew_mean        | 394      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 5295     |\n",
      "|    total_timesteps    | 885000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0754  |\n",
      "|    explained_variance | 0.961    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.152   |\n",
      "|    value_loss         | 19.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 90.9     |\n",
      "|    ep_rew_mean        | 446      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 5386     |\n",
      "|    total_timesteps    | 900000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0743  |\n",
      "|    explained_variance | 0.975    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -0.019   |\n",
      "|    value_loss         | 7.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 98       |\n",
      "|    ep_rew_mean        | 386      |\n",
      "| time/                 |          |\n",
      "|    fps                | 167      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 5479     |\n",
      "|    total_timesteps    | 915000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.124   |\n",
      "|    explained_variance | 0.00638  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -0.15    |\n",
      "|    value_loss         | 1.97e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 97.6     |\n",
      "|    ep_rew_mean        | 508      |\n",
      "| time/                 |          |\n",
      "|    fps                | 166      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 5570     |\n",
      "|    total_timesteps    | 930000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0566  |\n",
      "|    explained_variance | 0.0514   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.0532  |\n",
      "|    value_loss         | 1.07e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | 433      |\n",
      "| time/                 |          |\n",
      "|    fps                | 166      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 5662     |\n",
      "|    total_timesteps    | 945000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0544  |\n",
      "|    explained_variance | 0.848    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.226   |\n",
      "|    value_loss         | 57.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 425      |\n",
      "| time/                 |          |\n",
      "|    fps                | 166      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 5756     |\n",
      "|    total_timesteps    | 960000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0677  |\n",
      "|    explained_variance | -0.00514 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 0.0991   |\n",
      "|    value_loss         | 2.62e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 394      |\n",
      "| time/                 |          |\n",
      "|    fps                | 166      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 5850     |\n",
      "|    total_timesteps    | 975000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0664  |\n",
      "|    explained_variance | 0.854    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -0.267   |\n",
      "|    value_loss         | 40.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 113      |\n",
      "|    ep_rew_mean        | 680      |\n",
      "| time/                 |          |\n",
      "|    fps                | 166      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 5945     |\n",
      "|    total_timesteps    | 990000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0461  |\n",
      "|    explained_variance | 0.866    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -0.312   |\n",
      "|    value_loss         | 34.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 463      |\n",
      "| time/                 |          |\n",
      "|    fps                | 166      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 6043     |\n",
      "|    total_timesteps    | 1005000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0231  |\n",
      "|    explained_variance | 0.835    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.255   |\n",
      "|    value_loss         | 139      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 103      |\n",
      "|    ep_rew_mean        | 446      |\n",
      "| time/                 |          |\n",
      "|    fps                | 166      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 6138     |\n",
      "|    total_timesteps    | 1020000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0485  |\n",
      "|    explained_variance | 0.0573   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 0.185    |\n",
      "|    value_loss         | 3.12e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 451      |\n",
      "| time/                 |          |\n",
      "|    fps                | 166      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 6233     |\n",
      "|    total_timesteps    | 1035000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0644  |\n",
      "|    explained_variance | 0.0566   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -0.165   |\n",
      "|    value_loss         | 3.19e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 430      |\n",
      "| time/                 |          |\n",
      "|    fps                | 165      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 6328     |\n",
      "|    total_timesteps    | 1050000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0781  |\n",
      "|    explained_variance | 0.00956  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.296   |\n",
      "|    value_loss         | 2.59e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 98       |\n",
      "|    ep_rew_mean        | 610      |\n",
      "| time/                 |          |\n",
      "|    fps                | 165      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 6426     |\n",
      "|    total_timesteps    | 1065000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0586  |\n",
      "|    explained_variance | 0.944    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.136   |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.1     |\n",
      "|    ep_rew_mean        | 432      |\n",
      "| time/                 |          |\n",
      "|    fps                | 165      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 6531     |\n",
      "|    total_timesteps    | 1080000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0757  |\n",
      "|    explained_variance | 0.00367  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.302   |\n",
      "|    value_loss         | 1.32e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 371      |\n",
      "| time/                 |          |\n",
      "|    fps                | 165      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 6626     |\n",
      "|    total_timesteps    | 1095000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.068   |\n",
      "|    explained_variance | 0.847    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -0.0577  |\n",
      "|    value_loss         | 34.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 101      |\n",
      "|    ep_rew_mean        | 445      |\n",
      "| time/                 |          |\n",
      "|    fps                | 165      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 6721     |\n",
      "|    total_timesteps    | 1110000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0654  |\n",
      "|    explained_variance | 0.943    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -0.325   |\n",
      "|    value_loss         | 22.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 101      |\n",
      "|    ep_rew_mean        | 515      |\n",
      "| time/                 |          |\n",
      "|    fps                | 165      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 6817     |\n",
      "|    total_timesteps    | 1125000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0695  |\n",
      "|    explained_variance | 0.933    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -0.416   |\n",
      "|    value_loss         | 27.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | 470      |\n",
      "| time/                 |          |\n",
      "|    fps                | 164      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 6913     |\n",
      "|    total_timesteps    | 1140000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0693  |\n",
      "|    explained_variance | 0.672    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.0121  |\n",
      "|    value_loss         | 65.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 108      |\n",
      "|    ep_rew_mean        | 426      |\n",
      "| time/                 |          |\n",
      "|    fps                | 164      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 7009     |\n",
      "|    total_timesteps    | 1155000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0426  |\n",
      "|    explained_variance | 0.741    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -0.128   |\n",
      "|    value_loss         | 108      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 110      |\n",
      "|    ep_rew_mean        | 596      |\n",
      "| time/                 |          |\n",
      "|    fps                | 164      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 7104     |\n",
      "|    total_timesteps    | 1170000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0221  |\n",
      "|    explained_variance | 0.903    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 0.0382   |\n",
      "|    value_loss         | 80.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 113      |\n",
      "|    ep_rew_mean        | 567      |\n",
      "| time/                 |          |\n",
      "|    fps                | 164      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 7202     |\n",
      "|    total_timesteps    | 1185000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0315  |\n",
      "|    explained_variance | 0.0705   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 0.0315   |\n",
      "|    value_loss         | 3.31e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 555      |\n",
      "| time/                 |          |\n",
      "|    fps                | 164      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 7300     |\n",
      "|    total_timesteps    | 1200000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0292  |\n",
      "|    explained_variance | 0.0515   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -0.108   |\n",
      "|    value_loss         | 3.88e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 449      |\n",
      "| time/                 |          |\n",
      "|    fps                | 164      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 7399     |\n",
      "|    total_timesteps    | 1215000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0644  |\n",
      "|    explained_variance | 0.887    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 0.0309   |\n",
      "|    value_loss         | 50.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 411      |\n",
      "| time/                 |          |\n",
      "|    fps                | 164      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 7496     |\n",
      "|    total_timesteps    | 1230000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.101   |\n",
      "|    explained_variance | 0.901    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.0973   |\n",
      "|    value_loss         | 42.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | 502      |\n",
      "| time/                 |          |\n",
      "|    fps                | 163      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 7594     |\n",
      "|    total_timesteps    | 1245000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0726  |\n",
      "|    explained_variance | 0.829    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.212   |\n",
      "|    value_loss         | 54.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 583      |\n",
      "| time/                 |          |\n",
      "|    fps                | 163      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 7691     |\n",
      "|    total_timesteps    | 1260000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0143  |\n",
      "|    explained_variance | 0.875    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -0.0932  |\n",
      "|    value_loss         | 238      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | 633      |\n",
      "| time/                 |          |\n",
      "|    fps                | 163      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 7787     |\n",
      "|    total_timesteps    | 1275000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0126  |\n",
      "|    explained_variance | 0.937    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.0283   |\n",
      "|    value_loss         | 201      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | 623      |\n",
      "| time/                 |          |\n",
      "|    fps                | 163      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 7885     |\n",
      "|    total_timesteps    | 1290000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0147  |\n",
      "|    explained_variance | 0.588    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.0334  |\n",
      "|    value_loss         | 1.37e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 108      |\n",
      "|    ep_rew_mean        | 617      |\n",
      "| time/                 |          |\n",
      "|    fps                | 163      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 7982     |\n",
      "|    total_timesteps    | 1305000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0299  |\n",
      "|    explained_variance | -0.0308  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -0.02    |\n",
      "|    value_loss         | 4.55e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | 665      |\n",
      "| time/                 |          |\n",
      "|    fps                | 163      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 8079     |\n",
      "|    total_timesteps    | 1320000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0314  |\n",
      "|    explained_variance | 0.18     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.41    |\n",
      "|    value_loss         | 3.07e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 117      |\n",
      "|    ep_rew_mean        | 537      |\n",
      "| time/                 |          |\n",
      "|    fps                | 163      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 8174     |\n",
      "|    total_timesteps    | 1335000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0436  |\n",
      "|    explained_variance | 0.746    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -0.0823  |\n",
      "|    value_loss         | 59.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 127      |\n",
      "|    ep_rew_mean        | 445      |\n",
      "| time/                 |          |\n",
      "|    fps                | 163      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 8269     |\n",
      "|    total_timesteps    | 1350000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0758  |\n",
      "|    explained_variance | 0.935    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.163    |\n",
      "|    value_loss         | 111      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 117      |\n",
      "|    ep_rew_mean        | 439      |\n",
      "| time/                 |          |\n",
      "|    fps                | 162      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 8376     |\n",
      "|    total_timesteps    | 1365000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0379  |\n",
      "|    explained_variance | 0.103    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 0.0407   |\n",
      "|    value_loss         | 6.08e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 118      |\n",
      "|    ep_rew_mean        | 614      |\n",
      "| time/                 |          |\n",
      "|    fps                | 162      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 8472     |\n",
      "|    total_timesteps    | 1380000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0601  |\n",
      "|    explained_variance | 0.0429   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -0.365   |\n",
      "|    value_loss         | 6.63e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 118      |\n",
      "|    ep_rew_mean        | 488      |\n",
      "| time/                 |          |\n",
      "|    fps                | 162      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 8572     |\n",
      "|    total_timesteps    | 1395000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0727  |\n",
      "|    explained_variance | 0.0466   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -0.09    |\n",
      "|    value_loss         | 1.27e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 525      |\n",
      "| time/                 |          |\n",
      "|    fps                | 162      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 8674     |\n",
      "|    total_timesteps    | 1410000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0466  |\n",
      "|    explained_variance | 0.774    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -2.2     |\n",
      "|    value_loss         | 241      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.9     |\n",
      "|    ep_rew_mean        | 440      |\n",
      "| time/                 |          |\n",
      "|    fps                | 162      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 8776     |\n",
      "|    total_timesteps    | 1425000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0712  |\n",
      "|    explained_variance | 0.482    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -0.168   |\n",
      "|    value_loss         | 248      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 86.7     |\n",
      "|    ep_rew_mean        | 402      |\n",
      "| time/                 |          |\n",
      "|    fps                | 162      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 8878     |\n",
      "|    total_timesteps    | 1440000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0771  |\n",
      "|    explained_variance | -0.0363  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 4.83     |\n",
      "|    value_loss         | 3.29e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | 799      |\n",
      "| time/                 |          |\n",
      "|    fps                | 162      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 8977     |\n",
      "|    total_timesteps    | 1455000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.023   |\n",
      "|    explained_variance | 0.134    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.0277  |\n",
      "|    value_loss         | 2.47e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 567      |\n",
      "| time/                 |          |\n",
      "|    fps                | 161      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 9079     |\n",
      "|    total_timesteps    | 1470000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0656  |\n",
      "|    explained_variance | 0.0489   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 0.105    |\n",
      "|    value_loss         | 3.27e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 90       |\n",
      "|    ep_rew_mean        | 465      |\n",
      "| time/                 |          |\n",
      "|    fps                | 161      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 9181     |\n",
      "|    total_timesteps    | 1485000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0225  |\n",
      "|    explained_variance | 0.0329   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 5.02     |\n",
      "|    value_loss         | 4.47e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 41.8     |\n",
      "|    ep_rew_mean        | -4.35    |\n",
      "| time/                 |          |\n",
      "|    fps                | 161      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 9284     |\n",
      "|    total_timesteps    | 1500000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.154   |\n",
      "|    explained_variance | 0.641    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.0939   |\n",
      "|    value_loss         | 20.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 92.4     |\n",
      "|    ep_rew_mean        | 430      |\n",
      "| time/                 |          |\n",
      "|    fps                | 161      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 9385     |\n",
      "|    total_timesteps    | 1515000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0655  |\n",
      "|    explained_variance | 0.861    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -0.194   |\n",
      "|    value_loss         | 53.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.5     |\n",
      "|    ep_rew_mean        | 457      |\n",
      "| time/                 |          |\n",
      "|    fps                | 161      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 9484     |\n",
      "|    total_timesteps    | 1530000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0631  |\n",
      "|    explained_variance | 0.0726   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 2.41     |\n",
      "|    value_loss         | 3.55e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 96.7     |\n",
      "|    ep_rew_mean        | 427      |\n",
      "| time/                 |          |\n",
      "|    fps                | 161      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 9584     |\n",
      "|    total_timesteps    | 1545000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0686  |\n",
      "|    explained_variance | 0.893    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -0.511   |\n",
      "|    value_loss         | 104      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.4     |\n",
      "|    ep_rew_mean        | 514      |\n",
      "| time/                 |          |\n",
      "|    fps                | 161      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 9685     |\n",
      "|    total_timesteps    | 1560000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.064   |\n",
      "|    explained_variance | 0.0644   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 0.0361   |\n",
      "|    value_loss         | 1.92e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 509      |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 9785     |\n",
      "|    total_timesteps    | 1575000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0273  |\n",
      "|    explained_variance | 0.897    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.337   |\n",
      "|    value_loss         | 149      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | 610      |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 9883     |\n",
      "|    total_timesteps    | 1590000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0631  |\n",
      "|    explained_variance | 0.143    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -0.802   |\n",
      "|    value_loss         | 2.06e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 108      |\n",
      "|    ep_rew_mean        | 651      |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 9983     |\n",
      "|    total_timesteps    | 1605000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0392  |\n",
      "|    explained_variance | 0.053    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -0.337   |\n",
      "|    value_loss         | 3.41e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.6     |\n",
      "|    ep_rew_mean        | 608      |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 10081    |\n",
      "|    total_timesteps    | 1620000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0261  |\n",
      "|    explained_variance | 0.196    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.203   |\n",
      "|    value_loss         | 1.39e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 75.9     |\n",
      "|    ep_rew_mean        | 386      |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 10180    |\n",
      "|    total_timesteps    | 1635000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0342  |\n",
      "|    explained_variance | 0.854    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -0.0921  |\n",
      "|    value_loss         | 403      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 52.2     |\n",
      "|    ep_rew_mean        | 51.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 10287    |\n",
      "|    total_timesteps    | 1650000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.12    |\n",
      "|    explained_variance | 0.338    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 0.222    |\n",
      "|    value_loss         | 20.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 73.6     |\n",
      "|    ep_rew_mean        | 200      |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 10390    |\n",
      "|    total_timesteps    | 1665000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0969  |\n",
      "|    explained_variance | 0.947    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 0.125    |\n",
      "|    value_loss         | 42       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.3     |\n",
      "|    ep_rew_mean        | 573      |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 10492    |\n",
      "|    total_timesteps    | 1680000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0315  |\n",
      "|    explained_variance | 0.135    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -0.146   |\n",
      "|    value_loss         | 2.15e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.8     |\n",
      "|    ep_rew_mean        | 504      |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 10591    |\n",
      "|    total_timesteps    | 1695000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0434  |\n",
      "|    explained_variance | 0.0527   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -0.0481  |\n",
      "|    value_loss         | 1.97e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 96.6     |\n",
      "|    ep_rew_mean        | 575      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 10690    |\n",
      "|    total_timesteps    | 1710000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0399  |\n",
      "|    explained_variance | 0.924    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.0411  |\n",
      "|    value_loss         | 185      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 665      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 10790    |\n",
      "|    total_timesteps    | 1725000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0395  |\n",
      "|    explained_variance | 0.00772  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.168    |\n",
      "|    value_loss         | 4.24e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 115      |\n",
      "|    ep_rew_mean        | 486      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 10888    |\n",
      "|    total_timesteps    | 1740000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0263  |\n",
      "|    explained_variance | 0.0346   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.0504  |\n",
      "|    value_loss         | 4.55e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | 592      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 10987    |\n",
      "|    total_timesteps    | 1755000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0212  |\n",
      "|    explained_variance | 0.266    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 0.418    |\n",
      "|    value_loss         | 1.37e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | 629      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 11086    |\n",
      "|    total_timesteps    | 1770000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0134  |\n",
      "|    explained_variance | 0.783    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 0.00434  |\n",
      "|    value_loss         | 353      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 111      |\n",
      "|    ep_rew_mean        | 535      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 11185    |\n",
      "|    total_timesteps    | 1785000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0307  |\n",
      "|    explained_variance | 0.668    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -0.0686  |\n",
      "|    value_loss         | 339      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 667      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 11285    |\n",
      "|    total_timesteps    | 1800000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0268  |\n",
      "|    explained_variance | 0.832    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -0.452   |\n",
      "|    value_loss         | 1.2e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 108      |\n",
      "|    ep_rew_mean        | 613      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 11384    |\n",
      "|    total_timesteps    | 1815000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0136  |\n",
      "|    explained_variance | 0.163    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 0.519    |\n",
      "|    value_loss         | 3.49e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 111      |\n",
      "|    ep_rew_mean        | 701      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 11483    |\n",
      "|    total_timesteps    | 1830000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00434 |\n",
      "|    explained_variance | 0.603    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -0.253   |\n",
      "|    value_loss         | 6.2e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 112      |\n",
      "|    ep_rew_mean        | 649      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 11582    |\n",
      "|    total_timesteps    | 1845000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0214  |\n",
      "|    explained_variance | 0.238    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 2.87     |\n",
      "|    value_loss         | 7.5e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 98       |\n",
      "|    ep_rew_mean        | 388      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 11681    |\n",
      "|    total_timesteps    | 1860000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0658  |\n",
      "|    explained_variance | 0.888    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -0.037   |\n",
      "|    value_loss         | 65.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 607      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 11781    |\n",
      "|    total_timesteps    | 1875000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0294  |\n",
      "|    explained_variance | -0.0383  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.569    |\n",
      "|    value_loss         | 3.65e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.7     |\n",
      "|    ep_rew_mean        | 589      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 11882    |\n",
      "|    total_timesteps    | 1890000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0464  |\n",
      "|    explained_variance | 0.272    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.556   |\n",
      "|    value_loss         | 3.11e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 81.4     |\n",
      "|    ep_rew_mean        | 341      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 11984    |\n",
      "|    total_timesteps    | 1905000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0763  |\n",
      "|    explained_variance | 0.651    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 0.074    |\n",
      "|    value_loss         | 107      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 592      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 12086    |\n",
      "|    total_timesteps    | 1920000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0378  |\n",
      "|    explained_variance | 0.18     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -0.365   |\n",
      "|    value_loss         | 5.97e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 485      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 12186    |\n",
      "|    total_timesteps    | 1935000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00775 |\n",
      "|    explained_variance | 0.181    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 0.0128   |\n",
      "|    value_loss         | 2.65e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 653      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 12287    |\n",
      "|    total_timesteps    | 1950000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0323  |\n",
      "|    explained_variance | 0.285    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -0.161   |\n",
      "|    value_loss         | 6.81e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.8     |\n",
      "|    ep_rew_mean        | 485      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 12388    |\n",
      "|    total_timesteps    | 1965000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00964 |\n",
      "|    explained_variance | 0.323    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.162   |\n",
      "|    value_loss         | 2.31e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 98.1     |\n",
      "|    ep_rew_mean        | 635      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 12493    |\n",
      "|    total_timesteps    | 1980000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0234  |\n",
      "|    explained_variance | 0.929    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0.49    |\n",
      "|    value_loss         | 704      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.2     |\n",
      "|    ep_rew_mean        | 399      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 12602    |\n",
      "|    total_timesteps    | 1995000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0174  |\n",
      "|    explained_variance | 0.219    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -0.299   |\n",
      "|    value_loss         | 1.44e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 712      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 12702    |\n",
      "|    total_timesteps    | 2010000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0387  |\n",
      "|    explained_variance | 0.24     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -0.317   |\n",
      "|    value_loss         | 4.09e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 111      |\n",
      "|    ep_rew_mean        | 674      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 12803    |\n",
      "|    total_timesteps    | 2025000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0629  |\n",
      "|    explained_variance | 0.789    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -0.0597  |\n",
      "|    value_loss         | 299      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 101      |\n",
      "|    ep_rew_mean        | 565      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 12903    |\n",
      "|    total_timesteps    | 2040000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0412  |\n",
      "|    explained_variance | 0.862    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -0.415   |\n",
      "|    value_loss         | 341      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 543      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 13004    |\n",
      "|    total_timesteps    | 2055000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0378  |\n",
      "|    explained_variance | 0.88     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 0.0915   |\n",
      "|    value_loss         | 340      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 507      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 13107    |\n",
      "|    total_timesteps    | 2070000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0519  |\n",
      "|    explained_variance | 0.059    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 3.96     |\n",
      "|    value_loss         | 3.29e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 108      |\n",
      "|    ep_rew_mean        | 747      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 13209    |\n",
      "|    total_timesteps    | 2085000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0396  |\n",
      "|    explained_variance | 0.853    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -0.794   |\n",
      "|    value_loss         | 777      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 82.8     |\n",
      "|    ep_rew_mean        | 369      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 13311    |\n",
      "|    total_timesteps    | 2100000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0344  |\n",
      "|    explained_variance | 0.114    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -0.0391  |\n",
      "|    value_loss         | 3.25e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 90.6     |\n",
      "|    ep_rew_mean        | 559      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 13415    |\n",
      "|    total_timesteps    | 2115000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0424  |\n",
      "|    explained_variance | 0.208    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.0945  |\n",
      "|    value_loss         | 1.7e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.9     |\n",
      "|    ep_rew_mean        | 524      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 13517    |\n",
      "|    total_timesteps    | 2130000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0255  |\n",
      "|    explained_variance | 0.155    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 1.56     |\n",
      "|    value_loss         | 2.96e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 114      |\n",
      "|    ep_rew_mean        | 721      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 13619    |\n",
      "|    total_timesteps    | 2145000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0138  |\n",
      "|    explained_variance | 0.873    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 0.0144   |\n",
      "|    value_loss         | 824      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 112      |\n",
      "|    ep_rew_mean        | 769      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 13722    |\n",
      "|    total_timesteps    | 2160000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0124  |\n",
      "|    explained_variance | 0.417    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -0.183   |\n",
      "|    value_loss         | 7.97e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 110      |\n",
      "|    ep_rew_mean        | 678      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 13825    |\n",
      "|    total_timesteps    | 2175000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0164  |\n",
      "|    explained_variance | 0.817    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -0.106   |\n",
      "|    value_loss         | 542      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 619      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 13928    |\n",
      "|    total_timesteps    | 2190000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0138  |\n",
      "|    explained_variance | 0.872    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -0.0769  |\n",
      "|    value_loss         | 1.16e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | 567      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 14030    |\n",
      "|    total_timesteps    | 2205000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0361  |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -0.201   |\n",
      "|    value_loss         | 3.11e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 112      |\n",
      "|    ep_rew_mean        | 482      |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 14135    |\n",
      "|    total_timesteps    | 2220000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0289  |\n",
      "|    explained_variance | 0.793    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -0.161   |\n",
      "|    value_loss         | 672      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 110      |\n",
      "|    ep_rew_mean        | 534      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 14243    |\n",
      "|    total_timesteps    | 2235000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.041   |\n",
      "|    explained_variance | 0.0901   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.539   |\n",
      "|    value_loss         | 5.36e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 450      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 14354    |\n",
      "|    total_timesteps    | 2250000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00886 |\n",
      "|    explained_variance | 0.145    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -0.041   |\n",
      "|    value_loss         | 2.86e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 563      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 14468    |\n",
      "|    total_timesteps    | 2265000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0485  |\n",
      "|    explained_variance | 0.835    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 0.779    |\n",
      "|    value_loss         | 340      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 98.8     |\n",
      "|    ep_rew_mean        | 464      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 14578    |\n",
      "|    total_timesteps    | 2280000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0306  |\n",
      "|    explained_variance | 0.175    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 0.0893   |\n",
      "|    value_loss         | 2.13e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 86.9     |\n",
      "|    ep_rew_mean        | 383      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 14686    |\n",
      "|    total_timesteps    | 2295000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0432  |\n",
      "|    explained_variance | 0.732    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -0.0336  |\n",
      "|    value_loss         | 193      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 85.9     |\n",
      "|    ep_rew_mean        | 426      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 14795    |\n",
      "|    total_timesteps    | 2310000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0341  |\n",
      "|    explained_variance | 0.151    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.00408  |\n",
      "|    value_loss         | 3.49e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 702      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 14902    |\n",
      "|    total_timesteps    | 2325000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0131  |\n",
      "|    explained_variance | 0.891    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -0.153   |\n",
      "|    value_loss         | 1.14e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 528      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 15007    |\n",
      "|    total_timesteps    | 2340000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0202  |\n",
      "|    explained_variance | 0.29     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.0969  |\n",
      "|    value_loss         | 2.85e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 90.8     |\n",
      "|    ep_rew_mean        | 413      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 15118    |\n",
      "|    total_timesteps    | 2355000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0406  |\n",
      "|    explained_variance | 0.11     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -0.357   |\n",
      "|    value_loss         | 2.06e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95.8     |\n",
      "|    ep_rew_mean        | 601      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 15233    |\n",
      "|    total_timesteps    | 2370000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00943 |\n",
      "|    explained_variance | 0.871    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -0.0602  |\n",
      "|    value_loss         | 1.51e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 630      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 15338    |\n",
      "|    total_timesteps    | 2385000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00504 |\n",
      "|    explained_variance | 0.033    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.0113  |\n",
      "|    value_loss         | 3.55e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 96.7     |\n",
      "|    ep_rew_mean        | 611      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 15441    |\n",
      "|    total_timesteps    | 2400000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0281  |\n",
      "|    explained_variance | 0.947    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.318   |\n",
      "|    value_loss         | 809      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | 678      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 15545    |\n",
      "|    total_timesteps    | 2415000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0374  |\n",
      "|    explained_variance | 0.282    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -0.0219  |\n",
      "|    value_loss         | 1.92e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | 548      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 15647    |\n",
      "|    total_timesteps    | 2430000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0168  |\n",
      "|    explained_variance | 0.818    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 0.188    |\n",
      "|    value_loss         | 584      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 98.8     |\n",
      "|    ep_rew_mean        | 551      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 15751    |\n",
      "|    total_timesteps    | 2445000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0245  |\n",
      "|    explained_variance | 0.793    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -0.00974 |\n",
      "|    value_loss         | 800      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 584      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 15855    |\n",
      "|    total_timesteps    | 2460000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0165  |\n",
      "|    explained_variance | 0.337    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -0.474   |\n",
      "|    value_loss         | 5.38e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 94.5     |\n",
      "|    ep_rew_mean        | 527      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 15959    |\n",
      "|    total_timesteps    | 2475000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0524  |\n",
      "|    explained_variance | 0.888    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -0.0408  |\n",
      "|    value_loss         | 469      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 101      |\n",
      "|    ep_rew_mean        | 576      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 16062    |\n",
      "|    total_timesteps    | 2490000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0358  |\n",
      "|    explained_variance | 0.886    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -0.613   |\n",
      "|    value_loss         | 608      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 593      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 16169    |\n",
      "|    total_timesteps    | 2505000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0445  |\n",
      "|    explained_variance | 0.0999   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -0.0877  |\n",
      "|    value_loss         | 3.39e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 504      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 16274    |\n",
      "|    total_timesteps    | 2520000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0386  |\n",
      "|    explained_variance | 0.0694   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -0.0907  |\n",
      "|    value_loss         | 2.57e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 125      |\n",
      "|    ep_rew_mean        | 658      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 16383    |\n",
      "|    total_timesteps    | 2535000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0166  |\n",
      "|    explained_variance | 0.843    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -0.123   |\n",
      "|    value_loss         | 873      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 114      |\n",
      "|    ep_rew_mean        | 605      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 16490    |\n",
      "|    total_timesteps    | 2550000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0204  |\n",
      "|    explained_variance | 0.0179   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 0.0354   |\n",
      "|    value_loss         | 1.44e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 116      |\n",
      "|    ep_rew_mean        | 511      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 16593    |\n",
      "|    total_timesteps    | 2565000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0202  |\n",
      "|    explained_variance | 0.266    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.0907  |\n",
      "|    value_loss         | 2.58e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 113      |\n",
      "|    ep_rew_mean        | 578      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 16697    |\n",
      "|    total_timesteps    | 2580000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0145  |\n",
      "|    explained_variance | 0.765    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.00571 |\n",
      "|    value_loss         | 391      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | 484      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 16802    |\n",
      "|    total_timesteps    | 2595000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0377  |\n",
      "|    explained_variance | 0.106    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 6.18     |\n",
      "|    value_loss         | 1.89e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 111      |\n",
      "|    ep_rew_mean        | 482      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 16905    |\n",
      "|    total_timesteps    | 2610000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0592  |\n",
      "|    explained_variance | 0.122    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -0.378   |\n",
      "|    value_loss         | 3.27e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 108      |\n",
      "|    ep_rew_mean        | 697      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 17008    |\n",
      "|    total_timesteps    | 2625000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0398  |\n",
      "|    explained_variance | 0.841    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -0.0794  |\n",
      "|    value_loss         | 689      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | 578      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 17113    |\n",
      "|    total_timesteps    | 2640000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0136  |\n",
      "|    explained_variance | 0.247    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -0.0318  |\n",
      "|    value_loss         | 2.44e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.3     |\n",
      "|    ep_rew_mean        | 441      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 17220    |\n",
      "|    total_timesteps    | 2655000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0358  |\n",
      "|    explained_variance | 0.107    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -0.077   |\n",
      "|    value_loss         | 3.14e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | 677      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 17324    |\n",
      "|    total_timesteps    | 2670000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0132  |\n",
      "|    explained_variance | 0.355    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -0.289   |\n",
      "|    value_loss         | 1.48e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 97.5     |\n",
      "|    ep_rew_mean        | 614      |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 17432    |\n",
      "|    total_timesteps    | 2685000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0158  |\n",
      "|    explained_variance | 0.00208  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 1.76     |\n",
      "|    value_loss         | 6.1e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | 737      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 17540    |\n",
      "|    total_timesteps    | 2700000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0115  |\n",
      "|    explained_variance | 0.2      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -0.00803 |\n",
      "|    value_loss         | 3.99e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 619      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 17645    |\n",
      "|    total_timesteps    | 2715000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0233  |\n",
      "|    explained_variance | 0.897    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 0.128    |\n",
      "|    value_loss         | 799      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 113      |\n",
      "|    ep_rew_mean        | 532      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 17750    |\n",
      "|    total_timesteps    | 2730000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0584  |\n",
      "|    explained_variance | 0.863    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 0.0571   |\n",
      "|    value_loss         | 148      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 586      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 17855    |\n",
      "|    total_timesteps    | 2745000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0129  |\n",
      "|    explained_variance | 0.843    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -0.0727  |\n",
      "|    value_loss         | 548      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | 578      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 17961    |\n",
      "|    total_timesteps    | 2760000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0197  |\n",
      "|    explained_variance | 0.257    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.631   |\n",
      "|    value_loss         | 4.96e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 94.5     |\n",
      "|    ep_rew_mean        | 670      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 18069    |\n",
      "|    total_timesteps    | 2775000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0148  |\n",
      "|    explained_variance | 0.86     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.15    |\n",
      "|    value_loss         | 1.57e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.3     |\n",
      "|    ep_rew_mean        | 718      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 18176    |\n",
      "|    total_timesteps    | 2790000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0236  |\n",
      "|    explained_variance | 0.779    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -0.592   |\n",
      "|    value_loss         | 2.08e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 89       |\n",
      "|    ep_rew_mean        | 439      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 18285    |\n",
      "|    total_timesteps    | 2805000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0331  |\n",
      "|    explained_variance | 0.186    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -0.00899 |\n",
      "|    value_loss         | 4.2e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 101      |\n",
      "|    ep_rew_mean        | 595      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 18392    |\n",
      "|    total_timesteps    | 2820000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0155  |\n",
      "|    explained_variance | 0.26     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -0.0549  |\n",
      "|    value_loss         | 2.1e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.5     |\n",
      "|    ep_rew_mean        | 431      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 18497    |\n",
      "|    total_timesteps    | 2835000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0272  |\n",
      "|    explained_variance | 0.095    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 0.137    |\n",
      "|    value_loss         | 1.28e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 573      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 18604    |\n",
      "|    total_timesteps    | 2850000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0213  |\n",
      "|    explained_variance | 0.939    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -0.255   |\n",
      "|    value_loss         | 663      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 734      |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 18725    |\n",
      "|    total_timesteps    | 2865000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0317  |\n",
      "|    explained_variance | 0.706    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.415   |\n",
      "|    value_loss         | 5.36e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74.8     |\n",
      "|    ep_rew_mean        | 221      |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 18831    |\n",
      "|    total_timesteps    | 2880000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0545  |\n",
      "|    explained_variance | 0.325    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    value_loss         | 1.13e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 82.8     |\n",
      "|    ep_rew_mean        | 156      |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 18938    |\n",
      "|    total_timesteps    | 2895000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0812  |\n",
      "|    explained_variance | 0.644    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -0.266   |\n",
      "|    value_loss         | 375      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 72.6     |\n",
      "|    ep_rew_mean        | 296      |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 19045    |\n",
      "|    total_timesteps    | 2910000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0397  |\n",
      "|    explained_variance | 0.29     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 0.186    |\n",
      "|    value_loss         | 5.87e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 79.1     |\n",
      "|    ep_rew_mean        | 416      |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 19150    |\n",
      "|    total_timesteps    | 2925000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0323  |\n",
      "|    explained_variance | 0.777    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 0.107    |\n",
      "|    value_loss         | 1.88e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 69.9     |\n",
      "|    ep_rew_mean        | -39.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 19255    |\n",
      "|    total_timesteps    | 2940000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0779  |\n",
      "|    explained_variance | 0.73     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 0.262    |\n",
      "|    value_loss         | 18.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 80.9     |\n",
      "|    ep_rew_mean        | 274      |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 19361    |\n",
      "|    total_timesteps    | 2955000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.12    |\n",
      "|    explained_variance | 0.849    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -0.181   |\n",
      "|    value_loss         | 50.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 437      |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 19469    |\n",
      "|    total_timesteps    | 2970000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0308  |\n",
      "|    explained_variance | 0.871    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -0.136   |\n",
      "|    value_loss         | 676      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 564      |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 19572    |\n",
      "|    total_timesteps    | 2985000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.017   |\n",
      "|    explained_variance | 0.743    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -0.0305  |\n",
      "|    value_loss         | 395      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 114      |\n",
      "|    ep_rew_mean        | 725      |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 19674    |\n",
      "|    total_timesteps    | 3000000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0159  |\n",
      "|    explained_variance | 0.0761   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -0.0128  |\n",
      "|    value_loss         | 3.11e+04 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "model = A2C(\"CnnPolicy\", vec_env, verbose=1).learn(3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac1c98",
   "metadata": {
    "papermill": {
     "duration": 0.037512,
     "end_time": "2023-12-05T12:29:08.266471",
     "exception": false,
     "start_time": "2023-12-05T12:29:08.228959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test our model with 1000 steps and record all plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c10f33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:29:08.351366Z",
     "iopub.status.busy": "2023-12-05T12:29:08.349355Z",
     "iopub.status.idle": "2023-12-05T12:31:10.001292Z",
     "shell.execute_reply": "2023-12-05T12:31:09.999958Z"
    },
    "papermill": {
     "duration": 121.698561,
     "end_time": "2023-12-05T12:31:10.004223",
     "exception": false,
     "start_time": "2023-12-05T12:29:08.305662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Action:  [1 0 1 0 4 1 0 1 0 0 4 1 4 4 0 0 0 0 0 1 0 0 1 4 1 0 0 1 0 0]\n",
      "reward= [  0.   0.   0.   0. -10.   0.   0.   0.   0.   0. -10.   0. -10. -10.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. -10.   0.   0.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 10\n",
      "Action:  [1 4 0 0 1 0 4 0 1 0 0 0 0 0 0 0 1 4 4 0 4 4 0 0 4 0 0 1 4 1]\n",
      "reward= [ 0.  5.  0.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.\n",
      "  5.  0. -5.  5.  0.  0.  5.  0.  0.  0.  5.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 20\n",
      "Action:  [0 4 4 0 4 1 4 4 0 4 1 4 4 0 1 0 4 4 1 1 0 1 0 4 0 4 0 4 4 1]\n",
      "reward= [  0. -15.   0.   0.   5.   0.   5.   5.   0.  -5.   0.   5.   0.   0.\n",
      "   0.   0.  -5.   5.   0.   0.   0.   0.   0.  -5.   0.   5.   0.   0.\n",
      "   5.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 30\n",
      "Action:  [0 0 0 1 0 0 0 0 4 0 4 0 0 0 0 0 4 0 0 4 0 0 4 0 1 4 4 0 4 4]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   0.   0.   5.   0.  -5.   0.   0.   0.\n",
      "   0.   0.   5.   0.   0.   5.   0.   0. -10.   0.   0.   5.   5.   0.\n",
      "   5.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 40\n",
      "Action:  [0 0 0 4 0 0 1 4 4 4 0 4 0 4 0 0 4 0 0 0 4 0 0 0 1 4 0 4 4 0]\n",
      "reward= [ 0.  0.  0. -5.  0.  0.  0.  5.  5.  5.  0.  5.  0. -5.  0.  0.  5.  0.\n",
      "  0.  0.  5.  0.  0.  0.  0.  5.  0.  5.  5.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 50\n",
      "Action:  [1 4 0 0 0 4 0 1 0 0 0 0 4 1 0 4 0 4 0 4 0 4 0 4 4 0 0 0 0 0]\n",
      "reward= [   0.    5.    0.    0.    0.    5.    0.    0.    0.    0.    0.    0.\n",
      "    5.    0.    0.    0.    0. 1065.    0.    5.    0. 2005.    0. 1005.\n",
      "    0.    0.    0.    0.    0.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 60\n",
      "Action:  [0 0 4 1 0 0 0 4 0 4 4 0 0 4 1 0 0 0 0 0 4 0 4 0 4 0 0 0 0 0]\n",
      "reward= [ 0.  0.  5.  0.  0.  0.  0. -5.  0. -5.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  5.  0.  5.  0.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 70\n",
      "Action:  [0 4 0 0 1 0 0 0 4 0 0 0 0 0 0 4 4 0 0 0 1 0 0 4 0 0 0 4 0 4]\n",
      "reward= [  0.   5.   0.   0.   0.   0.   0.   0.   5.   0.   0.   0.   0.   0.\n",
      "   0. -10.  -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.\n",
      "   0.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 80\n",
      "Action:  [0 0 0 0 0 0 0 0 4 1 0 0 0 0 0 4 0 0 0 0 0 4 0 4 1 0 0 0 4 0]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   0.   0.   5.   0.   0. -20.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.   0.   0.   0.   0.\n",
      "   5.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 90\n",
      "Action:  [0 4 0 0 0 0 0 0 0 0 0 4 0 0 4 4 0 0 0 0 0 0 4 0 1 0 0 0 0 0]\n",
      "reward= [ 0.  0.  0.  0.  0.  0. -5.  0.  0.  0.  0.  5.  0.  0.  5. -5. -5.  0.\n",
      "  0.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 100\n",
      "Action:  [4 4 0 0 0 1 4 0 4 0 1 0 0 0 0 0 0 0 0 0 4 0 4 0 0 0 0 0 0 0]\n",
      "reward= [-10.   5.   0.   0.   0.   0.   5.  40.   5.   0.   0.   0.   0.   0.\n",
      " -15.   0.   0.   0.   0.   0.   5.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  -5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 110\n",
      "Action:  [4 0 0 0 0 0 0 0 4 0 4 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "reward= [  5.   0.  -5.   0.   0.   0.   0.   0.   5.   0.   5.   0.   0.   0.\n",
      "   5.   0.   0. -15.   0.   0.   0.   0.   0.   0.  40.   0.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False]\n",
      "Step 120\n",
      "Action:  [0 0 1 0 4 0 0 4 4 0 0 4 0 0 1 1 0 1 0 0 4 0 0 4 4 0 0 4 4 0]\n",
      "reward= [  0.   0.   0.   0.  -5.   0.   0.   5.  -5.   0.   0.   5.  40.   0.\n",
      "   0.   0.   0.   0.   0.   0.   5.   0.   0.   5.   0.   0.   0.  -5.\n",
      " -10.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 130\n",
      "Action:  [0 4 4 0 0 0 1 0 4 0 4 0 4 0 1 0 1 0 4 0 0 0 0 4 4 0 4 0 4 0]\n",
      "reward= [  0.  -5.   5.   0.   0.   0.   0.   0.   0.   0.   5.   0.  -5.   0.\n",
      "   0.   0.   0.   0.   5.  80.   0.   0.   0.  -5.   5.   0. -10.   0.\n",
      "   5.   0.] done= [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 140\n",
      "Action:  [1 0 4 0 4 0 0 0 4 4 0 0 4 0 0 0 0 0 0 1 0 0 4 0 0 0 0 4 0 1]\n",
      "reward= [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  5.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0. -5.  0.  0.  0.  0. -5.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 150\n",
      "Action:  [0 0 0 4 0 1 0 0 4 0 1 0 0 1 0 0 0 4 0 4 0 4 4 1 0 1 0 4 0 1]\n",
      "reward= [ 0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.\n",
      "  0. -5.  0.  5.  5.  0.  0.  0.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 160\n",
      "Action:  [4 0 0 1 0 4 1 0 0 4 0 1 0 4 0 0 0 0 0 0 0 4 0 0 0 4 0 0 4 4]\n",
      "reward= [  5.   0.   0.   0.   0.   5.   0.   0.   0.   5.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   5.   0.   0.   0.   5.   0.   0.\n",
      " -10.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 170\n",
      "Action:  [0 0 4 4 1 0 0 4 1 0 4 0 0 0 0 0 0 4 4 0 0 0 0 4 4 4 0 0 0 0]\n",
      "reward= [ -10.    0. 1025.    5.    0.    0.    0.    5.    0.    0.    5.    0.\n",
      "    0.    0.    0.    0.    0.    0.    5.    0.    0.    0.    0.    5.\n",
      "    5.    5.    0.    0.    0.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 180\n",
      "Action:  [0 1 0 0 0 4 0 0 0 1 1 4 4 0 0 0 0 4 4 0 0 4 0 4 0 4 0 0 0 4]\n",
      "reward= [  0.   0.   0.   0.   0.   5.   0.   0.   0.   0.   0.   0.   5.   0.\n",
      "   0.   0.   0. -10.   5.   0.   0.   5.   0.   5.   0.   5.   0.   0.\n",
      "   0.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 190\n",
      "Action:  [0 0 0 4 0 0 4 0 0 0 0 0 4 1 0 4 1 4 1 1 0 0 0 0 0 0 0 4 0 0]\n",
      "reward= [ 0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0. -5.  0.  0.  5.  0.  5.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 200\n",
      "Action:  [0 0 4 0 0 0 0 4 0 0 4 0 0 4 0 0 0 0 0 0 0 4 0 0 4 1 0 0 0 0]\n",
      "reward= [  0.   0.   5.   0.   0.   0.   0.   5.   0. -15.   5.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   5.   0.   0.  -5.   0.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 210\n",
      "Action:  [0 4 0 0 0 0 0 1 0 0 0 0 0 4 1 0 1 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
      "reward= [  0.  -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.\n",
      "   0.   0.   0.  -5.   0.   0.   0.   0. -10.   0.   0.   0.   0.   0.\n",
      " -10.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 220\n",
      "Action:  [0 0 1 0 0 0 0 1 0 0 0 0 0 4 0 0 0 0 0 0 1 0 1 0 0 4 0 0 0 1]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.   0. -15.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 230\n",
      "Action:  [4 0 4 4 0 0 0 4 1 4 4 0 0 0 0 0 4 0 1 0 0 0 4 1 0 0 0 0 0 4]\n",
      "reward= [   5.    0.   -5.    5.    0.    0.    0.    5.    0. 1125.    5.    0.\n",
      "    0.    0.    0.    0.    5.    0.    0.    0.    0.    0.  -10.    0.\n",
      "    0.    0.    0.    0.    0.    5.] done= [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 240\n",
      "Action:  [4 4 1 0 4 0 0 0 0 4 0 0 1 0 0 1 0 0 0 0 1 0 4 0 1 0 4 0 0 4]\n",
      "reward= [   5.   -5.    0.    0.    5.    0.    0.    0.    0.  -15.    0. 1000.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.    0.\n",
      "    0.    0.   -5.    0.    0.    5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 250\n",
      "Action:  [4 0 0 0 0 4 1 0 0 0 1 0 4 0 0 0 0 0 4 0 0 0 1 4 0 4 4 0 4 0]\n",
      "reward= [ -5.   0.   0.   0.   0.   5.   0.   0.   0.   0.   0.   0.   5.   0.\n",
      "   0.   0.   0.   0.   5.   0.   0.  -5.   0.   5.   0. -10.  -5.   0.\n",
      "   5.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 260\n",
      "Action:  [0 0 0 0 0 0 1 0 0 0 0 0 1 0 4 0 4 4 0 0 4 0 0 0 0 4 4 0 0 4]\n",
      "reward= [  0.  -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   5. -10.   5.   5.   0.   0.  -5.   0.   0.   0.   0.   0.   5.   0.\n",
      "   0.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 270\n",
      "Action:  [4 0 0 0 0 0 0 4 0 0 4 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 4 1 0]\n",
      "reward= [ -5.   0.   0.   0.   0.   0.   0.   5.   0.   0. -10.   0.   0.   0.\n",
      " -15.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.\n",
      "   0.   0.] done= [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 280\n",
      "Action:  [0 4 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 4 0 0 4 0 0 1 0 4 0]\n",
      "reward= [  0. -10.  -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. -10.   0.   0.   5.   0.   0.   0.   0.\n",
      "   5.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 290\n",
      "Action:  [0 1 0 4 4 4 0 0 0 4 0 0 4 1 1 0 0 4 4 4 0 4 0 0 4 1 0 0 0 4]\n",
      "reward= [ 0.  0.  0. -5.  5.  5.  0.  0.  0.  5.  0.  0. -5.  0.  0.  0.  0.  5.\n",
      "  5.  5.  0.  5.  0.  0.  5.  0.  0.  0.  0. -5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 300\n",
      "Action:  [4 4 4 0 1 0 0 0 1 0 0 4 0 0 0 1 0 0 4 0 4 0 0 4 0 0 4 0 0 0]\n",
      "reward= [-10.  -5.   5.   0.   0.   0.   0.   0.   0.   0.   0.  -5.   0.   0.\n",
      "   0.   0.   0.   0.   5.   0.   5.   0.   0.   5.   0.   0.   5.   0.\n",
      "   0.  -5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 310\n",
      "Action:  [0 1 0 1 0 0 0 0 0 4 0 4 1 0 0 4 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
      "reward= [  0.   0.   0.   0.   0.   0.  -5.  40.   0.   5.   0.   5.   0.   0.\n",
      "   0.   5.   0. -10.   0.   5.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 320\n",
      "Action:  [0 0 0 0 4 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 4]\n",
      "reward= [  0.   0.   0.   0.   5.   0.   0.   0.   0.   0.   0.   0.   0. -10.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.\n",
      "   0.   5.] done= [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 330\n",
      "Action:  [0 0 4 0 0 0 0 4 4 0 4 0 0 0 0 4 4 0 0 0 4 0 0 4 0 0 0 0 0 0]\n",
      "reward= [ 0.  0.  5.  0.  0.  0.  0. -5.  5.  0.  5.  0. -5.  0.  0. -5. -5.  0.\n",
      "  0.  0.  5.  0.  0.  5.  0.  0.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 340\n",
      "Action:  [0 0 4 0 0 1 4 1 0 1 0 4 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 1 1]\n",
      "reward= [0. 0. 5. 0. 0. 0. 5. 0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 350\n",
      "Action:  [0 0 0 0 0 0 0 1 1 1 4 0 0 4 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4 4]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.   0.   0. -10.\n",
      "   0.   0.   0.   0.   0.   0.   0. -15.   0.   0.   0.   0.   0.   0.\n",
      "   0.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False]\n",
      "Step 360\n",
      "Action:  [1 4 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 4 0 4 0 1 0 0 0 1 1 0 0]\n",
      "reward= [0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 0. 5. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False]\n",
      "Step 370\n",
      "Action:  [0 0 0 0 4 0 0 0 0 0 4 4 1 4 0 0 0 1 0 0 0 0 0 0 0 4 0 0 0 1]\n",
      "reward= [ 0.  0.  0.  0.  5.  0.  0.  0. -5.  0.  0. -5.  0.  5.  0.  0.  0.  0.\n",
      "  0.  0.  0. 80.  0.  0.  0.  5.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 380\n",
      "Action:  [0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 4 0 1 0 4 4 0 4]\n",
      "reward= [0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 0. 0. 5. 0.\n",
      " 0. 0. 5. 0. 0. 5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 390\n",
      "Action:  [4 4 0 0 0 0 0 0 0 0 0 0 4 0 0 0 1 1 4 0 0 0 0 0 0 0 0 4 0 0]\n",
      "reward= [ 5.  0.  0. -5.  0.  0.  0.  0.  0.  0.  0.  0.  5.  0. -5.  0.  0.  0.\n",
      "  5.  0. 80.  0.  0.  0.  0.  0.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 400\n",
      "Action:  [0 0 0 0 0 4 0 4 4 0 0 0 0 0 0 0 4 4 4 0 1 1 0 4 1 4 0 0 0 0]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   0.   5.  -5.   0. -15.   0.   0.   0.\n",
      "   0.   0.   0.   5.   5.   0.   0.   0.   0. -10.   0.   5.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 410\n",
      "Action:  [0 0 1 0 0 0 0 0 1 0 0 4 0 0 1 0 0 0 4 0 0 0 4 0 0 0 0 0 0 4]\n",
      "reward= [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  0.  0.  0.  0. -5.  0.\n",
      "  5.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 420\n",
      "Action:  [0 4 4 0 0 0 0 0 0 0 1 0 0 0 0 0 4 0 4 0 4 0 4 0 0 4 4 0 0 0]\n",
      "reward= [  0.   5. -10.   0.   0.   0.   0. -10.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0. -10.   0.   5.   0.   5.   0.   0.   0.   0.   5.   5.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 430\n",
      "Action:  [4 0 4 1 0 0 0 0 0 4 0 0 4 0 0 1 4 0 0 0 4 1 1 4 4 4 0 0 0 4]\n",
      "reward= [   5.    0.    5.    0.    0.    0.    0.   80.    0.    5.    0.    0.\n",
      "   -5.    0.    0.    0.    5.    0.    0.    0.    5.    0.    0.    5.\n",
      "   -5. 1005.    0.    0.    0.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True]\n",
      "Step 440\n",
      "Action:  [0 0 0 1 0 0 0 4 1 4 0 0 1 0 0 4 0 0 1 0 1 4 0 0 0 0 0 0 0 4]\n",
      "reward= [ 0.  0.  0.  0.  0.  0.  0.  0.  0. -5.  0.  0.  0.  0.  0.  0.  0. 80.\n",
      "  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 450\n",
      "Action:  [0 0 0 4 0 0 1 0 0 4 0 0 0 0 1 0 0 0 1 0 0 0 4 0 0 1 0 0 0 4]\n",
      "reward= [0. 0. 0. 5. 0. 0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 0.\n",
      " 0. 0. 0. 0. 0. 5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 460\n",
      "Action:  [0 0 0 4 0 4 0 0 0 4 0 0 0 0 4 0 4 0 0 0 0 0 0 4 0 0 0 0 0 0]\n",
      "reward= [  0.   0.   0.   5. -10.   5.   0.   0.   0.  -5.   0.   0.   0.   0.\n",
      "   5.   0.   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False]\n",
      "Step 470\n",
      "Action:  [0 0 0 0 0 0 0 1 0 0 1 0 4 0 4 0 0 1 4 0 0 0 0 0 4 0 4 0 1 0]\n",
      "reward= [ 0.  0.  0.  0.  0.  0.  0.  0. -5.  0.  0.  0. -5.  0.  5.  0.  0.  0.\n",
      "  5. 80.  0.  0.  0.  0.  5.  0. -5.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 480\n",
      "Action:  [0 0 4 0 0 0 0 0 0 4 0 0 0 4 0 0 0 4 0 0 0 0 0 0 4 0 1 0 4 4]\n",
      "reward= [  0.   0.   5.   0.   0.   0.   0.   0.   0.   5.   0.   0.   0.   5.\n",
      "   0.   0.   0.   5.   0.   0.   0.   0.   0.   0. -15.   0.   0.   0.\n",
      "   5.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 490\n",
      "Action:  [4 0 4 0 4 4 0 0 0 0 0 1 1 4 4 0 0 1 4 0 0 0 4 1 1 0 1 0 1 0]\n",
      "reward= [  5.   0.   5.   0.   5.   5.   0.   0.   0.   0.   0.   0.   0.  -5.\n",
      "   5.   0.   0.   0.   5.   0.   0.   0. -10.   0.   0.  -5.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False]\n",
      "Step 500\n",
      "Action:  [0 1 0 1 0 0 0 0 0 0 0 1 4 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0]\n",
      "reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 5. 0.] done= [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 510\n",
      "Action:  [4 4 0 0 0 0 0 0 0 0 0 4 0 0 4 0 0 0 0 0 1 0 0 4 0 0 0 0 1 4]\n",
      "reward= [  5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  -5.   0.   0.\n",
      " -10.   0.   0.   0.   0.   0.   0. -10.   0.   0.   0.   0.   0.   0.\n",
      "   0.   5.] done= [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 520\n",
      "Action:  [1 4 0 0 4 1 4 1 0 4 0 0 0 0 0 1 0 0 0 0 0 4 0 4 1 0 4 4 0 0]\n",
      "reward= [  0.   5.   0.   0.   0.   0.   0.   0.   0.   5.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. -10.   0.   0.   0.   5.   5.\n",
      "   0. -10.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False  True False False]\n",
      "Step 530\n",
      "Action:  [0 0 0 4 0 1 0 0 1 0 0 0 0 0 0 0 0 1 4 4 4 4 0 0 0 0 0 0 4 0]\n",
      "reward= [  0.   0.   0.   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   5.   5.   0. -10.   0.   0.   0.   0.   0.   0.\n",
      "   5.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 540\n",
      "Action:  [0 4 1 1 0 0 0 0 4 0 1 0 0 4 0 4 0 0 0 0 4 0 4 4 0 0 0 0 4 4]\n",
      "reward= [ 0.  5.  0.  0.  0.  0.  0.  0.  5.  0.  0.  0.  0.  5.  0.  0.  0.  0.\n",
      "  0.  0. -5.  0.  5.  5.  0.  0.  0.  0.  5.  5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 550\n",
      "Action:  [0 4 4 4 4 0 0 0 0 1 0 0 0 4 1 0 0 0 0 0 4 4 0 0 0 0 0 4 0 1]\n",
      "reward= [ 0.  0.  5.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  0.  0.  0.  0.\n",
      "  0.  0. -5.  5.  0.  0. 80.  0.  0.  5.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 560\n",
      "Action:  [0 0 0 4 0 0 0 4 0 0 4 1 4 0 0 1 1 0 0 0 0 0 0 0 0 0 0 4 0 0]\n",
      "reward= [ 0.  0.  0.  5.  0.  0.  0.  5.  0.  0.  5.  0. -5.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 570\n",
      "Action:  [0 4 0 0 0 0 0 0 0 1 0 4 4 0 4 0 1 0 0 0 0 0 0 0 4 1 0 0 0 0]\n",
      "reward= [  0.   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.   5.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. -15.   5.   0.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 580\n",
      "Action:  [4 0 0 0 0 0 1 0 0 4 4 0 4 0 0 1 4 0 0 0 0 0 1 0 0 4 0 0 0 0]\n",
      "reward= [  5.   0.   0.   0.   0.   0.   0.   0.   0.  -5.   5.   0. -10.  80.\n",
      "   0.   0.   5.   0.   0.   0.   0.   0.   0.   0.   0.   5.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 590\n",
      "Action:  [0 0 0 1 1 0 0 4 0 0 1 0 4 0 0 0 0 0 1 0 1 0 0 0 4 0 0 4 0 0]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   0.   5.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5. -10.   0.   5.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 600\n",
      "Action:  [1 0 0 0 0 0 0 4 0 0 0 0 4 4 4 0 0 1 1 0 4 1 0 0 0 4 0 1 4 4]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   0.   5.   0.   0.   0.   0. -15.   5.\n",
      "   5.   0.   0.   0.   0.  80.   5.   0.   0.   0.   0.  85.   0.   0.\n",
      "  -5.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False]\n",
      "Step 610\n",
      "Action:  [1 0 0 0 0 0 4 4 4 4 0 0 4 0 0 0 4 4 0 0 1 4 0 0 4 0 0 1 0 0]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   5.   5.   5.   0.   0.   0.   5.   0.\n",
      "   0.   0.   5.   5.   0.   0.   0.   0. -15.   0.  -5.   0.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 620\n",
      "Action:  [4 0 4 0 0 0 1 0 4 0 4 4 1 1 4 1 0 0 0 0 4 0 0 0 0 0 0 0 0 0]\n",
      "reward= [ 5.  0.  0.  0. -5.  0.  0.  0.  5.  0.  5.  5.  0.  0.  5.  0.  0.  0.\n",
      "  0.  0. -5.  0.  0.  0.  0.  0.  0.  0.  0. 80.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 630\n",
      "Action:  [0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 4 0 0 4 4 1 4 0 0 0 0 4 4 0]\n",
      "reward= [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -5.  0.\n",
      "  0.  5.  5.  0.  5.  0.  0.  0.  0. -5.  5.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 640\n",
      "Action:  [4 0 0 0 0 1 1 4 0 4 0 0 0 1 4 0 0 0 4 0 4 4 4 1 0 0 4 0 1 4]\n",
      "reward= [   5.    0.   -5.    0.    0.    0.    0.    0.    0.    5.    0.    0.\n",
      "    0.    0.    5.    0.    0.    0. 1005.    0.    5.  -15.    5.    0.\n",
      "    0.    0.    5.    0.    0.   -5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 650\n",
      "Action:  [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 4 4 4 0 0 0 4 1 0 4 0 0 4 0 4]\n",
      "reward= [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  0.  0.  0.  0.  5. -5.  5.\n",
      "  0.  0.  0.  5.  0.  0. -5.  0.  0.  5.  0. -5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 660\n",
      "Action:  [4 4 0 0 0 1 0 0 0 0 0 4 4 0 0 4 4 1 0 4 0 0 0 4 1 0 4 0 1 4]\n",
      "reward= [-5.  0. 80.  0.  0.  0.  0.  0.  0.  0.  0.  5. -5.  0.  0.  5.  5.  0.\n",
      "  0.  5.  0.  0.  0.  5.  0.  0.  5.  0.  0.  5.] done= [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 670\n",
      "Action:  [4 0 1 4 4 0 4 4 0 0 0 1 4 0 0 0 4 1 4 0 0 4 0 0 0 4 1 4 0 0]\n",
      "reward= [   5.    0.    0.  -10.   -5.    0.    5.    5.    0.    0.    0.    0.\n",
      "  -15.    0.    0.    0.  -10.    0.    0.    0.    0.    5.    0.    0.\n",
      "    0. 1025.    0.    5.    0.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 680\n",
      "Action:  [4 1 4 0 1 0 0 4 0 0 0 4 1 0 4 0 0 0 0 0 4 1 1 0 0 0 0 0 0 0]\n",
      "reward= [ 5.  0.  5.  0.  0.  0.  0.  0.  0. -5.  0.  5.  0.  0. -5.  0.  0.  0.\n",
      "  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 690\n",
      "Action:  [4 0 0 4 0 0 0 0 0 4 1 4 4 0 0 4 4 4 4 0 1 4 4 0 0 4 0 0 1 0]\n",
      "reward= [ 5.  0.  0.  5.  0.  0.  0.  0.  0.  5.  0.  5.  5.  0.  0.  5.  0.  5.\n",
      "  5.  0.  0. -5.  5.  0.  0.  5.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 700\n",
      "Action:  [0 4 0 1 0 0 0 1 0 0 0 1 0 0 4 4 4 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "reward= [  0.   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   5.   5.   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -10.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 710\n",
      "Action:  [0 0 0 4 0 0 4 4 0 0 0 4 0 1 4 1 0 0 0 0 1 0 0 1 4 0 1 0 0 0]\n",
      "reward= [   0.    0.    0.    5.    0.    0.    0.    5.    0.    0.    0.    5.\n",
      "    0.    0.    5.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 1005.    0.    0.    0.    0.    0.] done= [False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 720\n",
      "Action:  [0 0 0 0 0 0 4 4 0 0 0 4 0 0 0 0 0 4 1 1 1 0 0 1 4 0 0 4 0 0]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   5.   5.   0.   0.   0.   5.   0.   0.\n",
      "   0.   0.   0.   5.   0.   0.   0.   0.   0.   0. -10.   0.   0. -10.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 730\n",
      "Action:  [0 0 4 0 0 1 0 0 0 0 0 0 4 4 1 0 0 0 1 1 0 0 0 4 0 0 1 0 4 0]\n",
      "reward= [  0. -15.   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.   5.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   5.   0.   0.   0.   0.\n",
      "   5.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 740\n",
      "Action:  [4 0 1 4 0 0 0 0 0 4 0 0 4 0 4 4 0 0 4 0 0 1 0 0 0 4 0 1 0 0]\n",
      "reward= [   5.    0.    0.    5.    0.    0.    0.    0.    0.    5.    0.    0.\n",
      "    5.    0.    5. 1005.    0.    0.    5.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 750\n",
      "Action:  [0 0 4 0 4 0 0 0 1 4 0 0 4 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "reward= [-5.  0.  5.  0.  5.  0.  0.  0.  0. -5.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0. -5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 760\n",
      "Action:  [0 4 0 0 0 0 4 4 4 0 0 0 4 4 4 1 0 0 4 0 0 0 0 0 0 0 0 4 4 0]\n",
      "reward= [  80.    5.    0.    0.    0.    0.    5.    5.    5.    0.    0.    0.\n",
      "    5.    5.    5.    0.    0.    0.    5.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    5. 1105.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 770\n",
      "Action:  [0 4 0 0 4 4 0 4 0 0 4 0 4 0 0 4 0 4 0 0 4 0 4 4 4 4 0 1 0 1]\n",
      "reward= [   0.    5.    0.    0. 1025.   -5.    0.    5.    0.    0.    5.  -15.\n",
      "    5.    0.    0.    0.    0.   -5.    0.    0.    5.    0.   -5.    5.\n",
      "    5.    5.    0.    0.    0.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 780\n",
      "Action:  [0 4 0 0 0 0 0 4 0 0 0 0 0 4 0 0 1 0 0 0 0 4 0 0 4 0 0 0 0 4]\n",
      "reward= [  0.  -5.   0.   0.   0.   0. -15.   5.   0.   0.   0.   0.   0.   5.\n",
      "   0.   0.   0.   0.   0.   0.   0.   5.   0.   0.   0.   0.   0.   0.\n",
      "   0.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 790\n",
      "Action:  [0 0 4 4 4 0 1 0 4 0 4 0 0 0 0 0 0 0 0 0 1 4 4 4 4 0 0 4 0 1]\n",
      "reward= [ 0.  0.  5.  5.  5.  0.  0.  0.  5.  0.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      " 80.  0.  0.  5.  5.  5.  5.  0.  0.  5.  0.  0.] done= [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 800\n",
      "Action:  [0 0 0 1 4 0 0 4 0 0 4 0 1 0 0 0 4 0 0 0 0 1 0 0 4 4 0 0 0 0]\n",
      "reward= [ 0.  0.  0.  0.  5.  0.  0.  5.  0.  0. -5.  0.  0.  0.  0.  0.  5.  0.\n",
      "  0.  0.  0.  0.  0.  0.  5.  5.  0.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 810\n",
      "Action:  [0 0 0 4 0 0 0 0 4 0 0 0 4 0 1 4 0 0 0 0 4 1 4 4 0 4 0 0 0 4]\n",
      "reward= [  0.  -5.   0.   5.   0.   0.   0.   0.   5.   0.   0.   0.   5.   0.\n",
      "   0.   5.   0.   0.   0.   0. -10.   0.   5.  -5.   0.   5.   0.   0.\n",
      "   0.   5.] done= [False False False False False False False False False False False  True\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False]\n",
      "Step 820\n",
      "Action:  [0 0 0 0 1 0 1 4 0 0 0 0 0 1 0 0 0 4 0 4 0 4 4 4 4 4 1 0 0 0]\n",
      "reward= [   0.    0.    0.    0.    0.    0.    0.    5.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    5.    0.    5.    0.    5.    5.    5.\n",
      " 1005.    5.    0.    0.    0.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False]\n",
      "Step 830\n",
      "Action:  [4 0 0 0 1 0 0 0 0 0 0 0 0 4 4 1 0 4 0 0 4 1 4 0 1 0 4 0 0 4]\n",
      "reward= [ 5.  0. -5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  5.  0.  0. -5.\n",
      "  0.  0.  5.  0.  5.  0.  0.  0.  5.  0.  0.  5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 840\n",
      "Action:  [0 0 0 0 0 0 0 4 1 0 0 0 0 0 4 0 4 0 0 4 0 0 1 4 0 4 0 0 0 0]\n",
      "reward= [   0.    0.    0.    0.    0.    0.    0.    5.    0.    0.    0.    0.\n",
      "    0.    0.    5.    0.  -10.    0.    0.   -5.    0.   -5.    0.    0.\n",
      "    0. 1085.    0.    0.    0.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 850\n",
      "Action:  [0 0 0 0 4 1 0 0 0 4 0 0 0 4 4 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "reward= [0. 0. 0. 0. 5. 0. 0. 0. 0. 5. 0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False  True False]\n",
      "Step 860\n",
      "Action:  [0 0 0 0 0 0 0 4 1 1 0 0 1 0 0 0 4 0 0 0 0 4 4 0 0 4 4 0 0 4]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   0. -10.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   5.   0.   0.   0.   0.   5.   5.   0.   0.   0.   5.   0.\n",
      "   0.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 870\n",
      "Action:  [0 0 0 0 0 4 0 0 4 0 0 4 0 0 0 0 0 4 0 0 0 0 4 0 0 0 0 1 0 1]\n",
      "reward= [  0.   0.   0.   0.   0.   5.   0.   0.   5.   0.   0.   5.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   5.   0. -10.   0.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False]\n",
      "Step 880\n",
      "Action:  [0 0 1 0 0 4 4 0 0 0 4 0 4 1 0 0 0 1 0 0 0 0 0 4 0 4 0 0 4 4]\n",
      "reward= [ 0.  0.  0.  0.  0.  0.  5.  0.  0.  0.  5.  0.  5.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  5.  0. -5.  0.  0.  0.  5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 890\n",
      "Action:  [4 0 4 0 0 0 1 4 4 0 1 0 0 0 0 4 0 1 4 0 1 0 4 0 0 4 0 0 0 0]\n",
      "reward= [-10.  -5.   0.   0.   0.   0.   0.   5.  -5.   0.   0.   0.   0.   0.\n",
      "   0.   5.  20.   0.   5.   0.   0.   0.   5.   0. -10. -10.   0.   0.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 900\n",
      "Action:  [4 0 4 0 0 0 0 4 4 0 0 0 0 0 4 1 4 0 0 0 0 0 0 1 0 1 0 0 4 4]\n",
      "reward= [  5.   0. -10.   0.   0.   0.   0.   5.   5.   0.   0.   0.   0.   0.\n",
      "   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   5.   5.] done= [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False]\n",
      "Step 910\n",
      "Action:  [4 4 0 0 1 0 4 0 0 0 0 0 4 4 0 1 4 4 0 0 0 0 0 0 1 4 0 0 0 4]\n",
      "reward= [   5.    5.    0.   -5.    0.    0.  -10.    0.    0.    0.    0.    0.\n",
      " 1005.    5.    0.    0.    5.    5.    0.    0.   -5.    0.    0.    0.\n",
      "    0.   -5. 1100.    0.    0.    5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 920\n",
      "Action:  [1 0 0 1 0 0 0 1 0 0 0 0 4 0 0 0 0 4 0 0 0 4 4 4 4 0 0 0 0 4]\n",
      "reward= [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    5.    0.    0.    0.    0.    5.    0.    0.    0.    5. 1045.    5.\n",
      "    0.    0.  -10.    0.    0.    5.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 930\n",
      "Action:  [0 0 0 4 1 4 0 0 0 0 0 1 1 0 0 4 0 0 0 1 0 4 1 4 4 1 0 0 4 1]\n",
      "reward= [  0.   0.   0.  -5.   0. -10.   0.   0.   0.   0. -15.   0.   0.   0.\n",
      "   0.   5.   0.   0.   0.   0.   0. -15.   0.   5.   5.   0.   0.   0.\n",
      "   5.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 940\n",
      "Action:  [0 1 0 1 0 1 4 4 0 0 0 1 0 0 4 0 0 0 4 0 4 0 0 0 0 4 4 4 0 0]\n",
      "reward= [  0.   0.   0.   0.   0.   0.   5. -10.   0.   0.   0.   0.   0.   0.\n",
      "   5.   0.   0.   0.  -5.   0.   5.   0.  -5.   0.   0.   5.   5. -10.\n",
      "   0.   0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False  True False False False]\n",
      "Step 950\n",
      "Action:  [0 4 0 0 0 4 0 4 0 0 0 4 0 0 0 4 0 0 0 0 4 0 0 0 4 0 0 0 1 0]\n",
      "reward= [   0.    5.    0.    0.    0.    5.    0. 1005.    0.   20.    0.    5.\n",
      "    0.    0.    0.    5.    0.    0.    0.    0.    5.    0.    0.    0.\n",
      "    5.    0.    0.    0.    0.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 960\n",
      "Action:  [0 0 0 0 0 1 0 4 0 4 0 4 0 1 4 0 0 0 4 4 4 0 1 0 1 0 4 0 4 0]\n",
      "reward= [ 0.  0. -5.  0.  0.  0.  0.  5.  0.  5.  0.  0.  0.  0.  5.  0.  0.  0.\n",
      "  5.  5. -5.  0.  0.  0.  0.  0.  5.  0.  0.  0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 970\n",
      "Action:  [0 0 1 0 0 0 0 0 4 1 0 0 1 0 0 4 4 0 1 0 4 0 0 0 4 0 4 0 4 1]\n",
      "reward= [   0.    0.    0.    0.    0.    0.    0.    0.  -15.    0.    0.    0.\n",
      "    0.    0.    0. 1005.    5.    0.    0.    0.    0.    0.    0.    0.\n",
      "    5.    0.    5.    0.  -15.    0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 980\n",
      "Action:  [0 4 1 0 0 0 0 1 0 0 0 1 0 4 0 0 0 0 0 4 0 1 4 0 0 0 0 0 4 0]\n",
      "reward= [0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 5. 0. 0. 5. 0.\n",
      " 0. 0. 0. 0. 5. 0.] done= [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Step 990\n",
      "Action:  [0 0 4 0 0 0 0 0 4 0 0 4 0 1 0 0 4 0 0 0 0 4 0 4 0 0 0 4 0 4]\n",
      "reward= [  0.   0.   5.   0.   0.   0.   0.   0.   5.   0.   0.   5.   0.   0.\n",
      "   0.   0.   5.   0.   0.   0.   0.   5.   0. -10.   0.   0.   0. -10.\n",
      "   0.   5.] done= [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Test the trained agent\n",
    "# using the vecenv\n",
    "obs = vec_env.reset()\n",
    "n_steps = 1000\n",
    "\n",
    "replay_folder = './replay'\n",
    "if os.path.exists(replay_folder):\n",
    "    shutil.rmtree(replay_folder)\n",
    "\n",
    "n_env = obs.shape[0] # Number of environments. A2C will play all envs\n",
    "ep_id = np.zeros(n_env, int)\n",
    "ep_steps = np.zeros(n_env, int)\n",
    "cum_reward = np.zeros(n_env)\n",
    "max_reward = -1e10\n",
    "max_game_id = 0\n",
    "max_ep_id = 0\n",
    "\n",
    "for step in range(n_steps):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(f\"Step {step}\")\n",
    "        print(\"Action: \", action)\n",
    "        print(\"reward=\", reward, \"done=\", done)\n",
    "        \n",
    "    for eID in range(n_env):\n",
    "        cum_reward[eID] += reward[eID]\n",
    "        folder = f'{replay_folder}/{eID}/{ep_id[eID]}'\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        fname = folder + '/' + '{:06d}'.format(ep_steps[eID]) + '.png'\n",
    "        cv2.imwrite(fname, obs[eID])\n",
    "        #cv2.imshow(\"Image\" + str(eID), obs[eID])\n",
    "        #cv2.waitKey(10)\n",
    "        ep_steps[eID] += 1\n",
    "        \n",
    "        if done[eID]:\n",
    "            if cum_reward[eID] > max_reward:\n",
    "                max_reward = cum_reward[eID]\n",
    "                max_game_id = eID\n",
    "                max_ep_id = ep_id[eID]\n",
    "                \n",
    "            ep_id[eID] += 1\n",
    "            cum_reward[eID] = 0\n",
    "            ep_steps[eID] = 0\n",
    "\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8820141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:31:10.105967Z",
     "iopub.status.busy": "2023-12-05T12:31:10.105475Z",
     "iopub.status.idle": "2023-12-05T12:31:10.111836Z",
     "shell.execute_reply": "2023-12-05T12:31:10.110514Z"
    },
    "papermill": {
     "duration": 0.059875,
     "end_time": "2023-12-05T12:31:10.114259",
     "exception": false,
     "start_time": "2023-12-05T12:31:10.054384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal reached!  Max reward= 4210.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Goal reached!\", \" Max reward=\", max_reward)\n",
    "best_replay_path = f'{replay_folder}/{max_game_id}/{max_ep_id}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e9514",
   "metadata": {
    "papermill": {
     "duration": 0.048734,
     "end_time": "2023-12-05T12:31:10.211809",
     "exception": false,
     "start_time": "2023-12-05T12:31:10.163075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make a gif image to visualize the best play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6adff22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:31:10.312387Z",
     "iopub.status.busy": "2023-12-05T12:31:10.311207Z",
     "iopub.status.idle": "2023-12-05T12:31:11.156827Z",
     "shell.execute_reply": "2023-12-05T12:31:11.155464Z"
    },
    "papermill": {
     "duration": 0.900434,
     "end_time": "2023-12-05T12:31:11.160094",
     "exception": false,
     "start_time": "2023-12-05T12:31:10.259660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3508690983.py:8: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(filename))\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import imageio\n",
    "\n",
    "filenames = sorted(glob.glob(best_replay_path + '/*.png'))\n",
    "\n",
    "images = []\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('replay.gif', images, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b650be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:31:11.260759Z",
     "iopub.status.busy": "2023-12-05T12:31:11.260316Z",
     "iopub.status.idle": "2023-12-05T12:31:11.289696Z",
     "shell.execute_reply": "2023-12-05T12:31:11.288775Z"
    },
    "papermill": {
     "duration": 0.082676,
     "end_time": "2023-12-05T12:31:11.292283",
     "exception": false,
     "start_time": "2023-12-05T12:31:11.209607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/gif": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='/kaggle/working/replay.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fbfa2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:31:11.399193Z",
     "iopub.status.busy": "2023-12-05T12:31:11.397733Z",
     "iopub.status.idle": "2023-12-05T12:31:11.634908Z",
     "shell.execute_reply": "2023-12-05T12:31:11.633641Z"
    },
    "papermill": {
     "duration": 0.293154,
     "end_time": "2023-12-05T12:31:11.637819",
     "exception": false,
     "start_time": "2023-12-05T12:31:11.344665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('your_studentID_a2c_30env_3M.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32d3d76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:31:11.739986Z",
     "iopub.status.busy": "2023-12-05T12:31:11.739489Z",
     "iopub.status.idle": "2023-12-05T12:31:11.749296Z",
     "shell.execute_reply": "2023-12-05T12:31:11.745414Z"
    },
    "papermill": {
     "duration": 0.064824,
     "end_time": "2023-12-05T12:31:11.752390",
     "exception": false,
     "start_time": "2023-12-05T12:31:11.687566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('tetris_best_score.csv', 'w') as fs:\n",
    "    fs.write('Id,Predicted\\n')\n",
    "    fs.write(f'game_score,{max_reward}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20124a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T12:31:11.858856Z",
     "iopub.status.busy": "2023-12-05T12:31:11.858308Z",
     "iopub.status.idle": "2023-12-05T12:31:11.868476Z",
     "shell.execute_reply": "2023-12-05T12:31:11.867326Z"
    },
    "papermill": {
     "duration": 0.066789,
     "end_time": "2023-12-05T12:31:11.871111",
     "exception": false,
     "start_time": "2023-12-05T12:31:11.804322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='tetris_best_score.csv' target='_blank'>tetris_best_score.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/tetris_best_score.csv"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload your results to Kaggle\n",
    "from IPython.display import FileLink\n",
    "FileLink('tetris_best_score.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7214678,
     "sourceId": 65534,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19862.376175,
   "end_time": "2023-12-05T12:31:14.612923",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-05T07:00:12.236748",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
